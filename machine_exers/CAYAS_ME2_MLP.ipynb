{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "lF-7IkQjUJLR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter-based MLP\n",
        "Using torch parameters with einops and einsum operations only\n",
        "\\\n",
        "\\\n",
        "Ryan Roi Cayas \\\n",
        "2022-22085\n"
      ],
      "metadata": {
        "id": "pWlJ4IVtUS-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "import random\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "_WZBxBjTn3cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load MNIST data"
      ],
      "metadata": {
        "id": "g6M_Wn-lUtJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define the transformations to apply to the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create the data loaders\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "h4qa_REeUqLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP Model using Einops and Einsum"
      ],
      "metadata": {
        "id": "C-zTpPn3VGXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from einops import rearrange, repeat, reduce\n",
        "from torch import einsum\n",
        "\n",
        "def fc_eins(input_size, output_size):\n",
        "    W = nn.Parameter(torch.randn(input_size, output_size) * 0.01)  # Weight initialization\n",
        "    b = nn.Parameter(torch.zeros(output_size))                     # Bias initialization\n",
        "\n",
        "    def fc_linear(x):\n",
        "      return torch.einsum('ij,jk->ik', x, W) + b\n",
        "    return fc_linear, W, b\n",
        "\n",
        "class MLP_eins(nn.Module):\n",
        "    def __init__(self, input_size=28*28, hidden_size=128, num_classes=10):\n",
        "        super(MLP_eins, self).__init__()\n",
        "\n",
        "        self.fc1_eins, self.W1, self.b1 = fc_eins(input_size, hidden_size)\n",
        "        self.fc2_eins, self.W2, self.b2 = fc_eins(hidden_size, num_classes)\n",
        "\n",
        "        # Register the parameters\n",
        "        self.register_parameter('W1', self.W1)\n",
        "        self.register_parameter('b1', self.b1)\n",
        "        self.register_parameter('W2', self.W2)\n",
        "        self.register_parameter('b2', self.b2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = rearrange(x, 'b c h w -> b (c h w)')  # Flatten the input tensor\n",
        "        y = self.fc1_eins(x)                      # Apply first FC layer\n",
        "        y = torch.maximum(y, torch.zeros_like(y)) # Apply ReLU activation\n",
        "        y = self.fc2_eins(y)                      # Apply second FC layer\n",
        "        return y\n",
        "\n",
        "\n",
        "# Create an instance of the MLP model\n",
        "model_eins = MLP_eins()\n",
        "x = torch.randn(64, 1, 28, 28)\n",
        "print(model_eins)\n",
        "print(model_eins(x).shape)\n",
        "\n",
        "# print the number of parameters\n",
        "num_params = sum(p.numel() for p in model_eins.parameters())\n",
        "# Use comma to print the number in a more readable format\n",
        "print(f\"Number of parameters: {num_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWjD6BRGdtE_",
        "outputId": "4363c213-bfc7-4085-a748-446985991205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP_eins()\n",
            "torch.Size([64, 10])\n",
            "Number of parameters: 101,770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the loss function and optimizer"
      ],
      "metadata": {
        "id": "aauwY5HseV5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "model_eins.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_eins.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "7vzMeWmkdi12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a2c3d5-6580-43ee-8590-81f1fe955ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "GFbdmA--eUIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "model_eins.train()\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_eins(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vrrt--mWBjY",
        "outputId": "cad7b479-a258-478e-baa4-c59bd0bf620c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:17<02:33, 17.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.4203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:33<02:13, 16.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Loss: 0.2048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:47<01:47, 15.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Loss: 0.1476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:01<01:28, 14.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Loss: 0.1184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:15<01:13, 14.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Loss: 0.1003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:29<00:57, 14.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Loss: 0.0882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:43<00:42, 14.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, Loss: 0.0781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [01:58<00:28, 14.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, Loss: 0.0730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [02:12<00:14, 14.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Loss: 0.0651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:26<00:00, 14.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.0598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model"
      ],
      "metadata": {
        "id": "cZG6zXGGeewM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_eins.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model_eins(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOSzhoZHeeOV",
        "outputId": "d05cbae8-9121-48dc-d82a-073f782c085f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VERIFY: MLP Model using Torch NN"
      ],
      "metadata": {
        "id": "lF-7IkQjUJLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=28*28, hidden_size=128, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input tensor\n",
        "        y = self.fc1(x)\n",
        "        y = self.relu(y)\n",
        "        y = self.fc2(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "# Create an instance of the MLP model\n",
        "model = MLP()\n",
        "x = torch.randn(64, 1, 28, 28)\n",
        "print(model)\n",
        "print(model(x).shape)\n",
        "\n",
        "# print the number of parameters\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "# Use comma to print the number in a more readable format\n",
        "print(f\"Number of parameters: {num_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LTVmOOKVrrQ",
        "outputId": "9a95ee37-129f-444f-99d8-b4dcbfe2bea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "torch.Size([64, 10])\n",
            "Number of parameters: 101,770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Jc-XbXGJVmQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "model.train()\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qSuq-AIUPmg",
        "outputId": "86338ffa-5e22-480a-c8ad-c418accbb1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:13<02:02, 13.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.3834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:29<01:58, 14.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Loss: 0.1913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:43<01:41, 14.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Loss: 0.1354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [00:57<01:25, 14.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Loss: 0.1089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:11<01:10, 14.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Loss: 0.0914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:24<00:55, 13.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Loss: 0.0809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:37<00:41, 13.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, Loss: 0.0720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [01:51<00:27, 13.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, Loss: 0.0627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [02:04<00:13, 13.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Loss: 0.0580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:18<00:00, 13.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Loss: 0.0548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSlH3XOAVweS",
        "outputId": "7b4b0826-d7e0-417f-9aa1-bf29672dcfae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The accuracy of the MLP implementation using einops and einsum is near the accuracy of the MLP algorithm using the nn module.\n",
        "\n",
        "## Accuracy using einops and einsum: 97.16 %\n",
        "## Accuracy using NN Module; 97.03 %"
      ],
      "metadata": {
        "id": "h9_1OjYQoFb3"
      }
    }
  ]
}