{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 1B Evaluation\n",
    "Ryan Roi Cayas\\\n",
    "2022-22085\n",
    "\n",
    "In this notebook, we replicate the published scores of the Llama 3.2 1B on the MGSM dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load libraries and set-up CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast\n",
    "from datasets import load_dataset, concatenate_datasets # Huggingface datasets (https://huggingface.co/docs/datasets/)\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "# Set-up CUDA device\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "# use a specific GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Use GPU for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print the device being used\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check the GPU name\n",
    "if device.type == 'cuda':\n",
    "    gpu_name = torch.cuda.get_device_name(0)  # 0 because CUDA_VISIBLE_DEVICES=4 means GPU 4 is now 0\n",
    "    print(\"Using GPU:\", gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the pre-trained tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to model and tokenizer\n",
    "model_dir = \"../../../../../llm/llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_dir, padding_side=\"left\")\n",
    "model = LlamaForCausalLM.from_pretrained(model_dir)\n",
    "\n",
    "# Set the eos_token as the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load the MGSM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading datasets: 100%|██████████| 11/11 [00:32<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'answer_number', 'equation_solution', 'language'],\n",
      "    num_rows: 88\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'answer_number', 'equation_solution', 'language'],\n",
      "    num_rows: 2750\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Languages: English, Spanish, French, German, Russian, Chinese, Japanese, Thai, Swahili, Bengali, Telugu\n",
    "languages = [\"en\",\"es\",\"fr\",\"de\",\"ru\",\"zh\",\"ja\",\"th\",\"sw\",\"bn\",\"te\"]\n",
    "\n",
    "# Empty list to store datasets with added 'language' feature\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "# Load the datasets and add the 'language' feature\n",
    "for lang in tqdm(languages, desc=\"Loading datasets\"):\n",
    "    # Load train and test datasets for the language\n",
    "    train = load_dataset(\"juletxara/mgsm\", lang, split=\"train\")\n",
    "    test = load_dataset(\"juletxara/mgsm\", lang, split=\"test\")\n",
    "    \n",
    "    # Add the 'language' feature to both train and test sets\n",
    "    train = train.add_column(\"language\", [lang] * len(train))\n",
    "    test = test.add_column(\"language\", [lang] * len(test))\n",
    "    \n",
    "    # Append the datasets with the 'language' feature to the lists\n",
    "    train_datasets.append(train)\n",
    "    test_datasets.append(test)\n",
    "\n",
    "# Concatenate datasets from all languages into a single train and test dataset\n",
    "mgsm_train = concatenate_datasets(train_datasets)\n",
    "mgsm_test = concatenate_datasets(test_datasets)\n",
    "\n",
    "# Verify the structure\n",
    "print(mgsm_train)\n",
    "print(mgsm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>equation_solution</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question: Roger has 5 tennis balls. He buys 2 ...</td>\n",
       "      <td>Step-by-Step Answer: Roger started with 5 ball...</td>\n",
       "      <td>11</td>\n",
       "      <td>5 + 6 = 11.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question: There were nine computers in the ser...</td>\n",
       "      <td>Step-by-Step Answer: There are 4 days from mon...</td>\n",
       "      <td>29</td>\n",
       "      <td>4 * 5 = 20. 9 + 20 = 29.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: Leah had 32 chocolates and her siste...</td>\n",
       "      <td>Step-by-Step Answer: Leah had 32 chocolates an...</td>\n",
       "      <td>39</td>\n",
       "      <td>32 + 42 = 74. 74 - 35 = 39.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Question: Shawn has five toys. For Christmas, ...</td>\n",
       "      <td>Step-by-Step Answer: He has 5 toys. He got 2 f...</td>\n",
       "      <td>9</td>\n",
       "      <td>5 + 2 = 7. 7 + 2 = 9.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question: Michael had 58 golf balls. On tuesda...</td>\n",
       "      <td>Step-by-Step Answer: Michael started with 58 g...</td>\n",
       "      <td>33</td>\n",
       "      <td>58 - 23 = 35. 35 - 2 = 33.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Question: Roger has 5 tennis balls. He buys 2 ...   \n",
       "1  Question: There were nine computers in the ser...   \n",
       "2  Question: Leah had 32 chocolates and her siste...   \n",
       "3  Question: Shawn has five toys. For Christmas, ...   \n",
       "4  Question: Michael had 58 golf balls. On tuesda...   \n",
       "\n",
       "                                              answer  answer_number  \\\n",
       "0  Step-by-Step Answer: Roger started with 5 ball...             11   \n",
       "1  Step-by-Step Answer: There are 4 days from mon...             29   \n",
       "2  Step-by-Step Answer: Leah had 32 chocolates an...             39   \n",
       "3  Step-by-Step Answer: He has 5 toys. He got 2 f...              9   \n",
       "4  Step-by-Step Answer: Michael started with 58 g...             33   \n",
       "\n",
       "             equation_solution language  \n",
       "0                  5 + 6 = 11.       en  \n",
       "1     4 * 5 = 20. 9 + 20 = 29.       en  \n",
       "2  32 + 42 = 74. 74 - 35 = 39.       en  \n",
       "3        5 + 2 = 7. 7 + 2 = 9.       en  \n",
       "4   58 - 23 = 35. 35 - 2 = 33.       en  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgsm_train.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>equation_solution</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>None</td>\n",
       "      <td>70000</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>None</td>\n",
       "      <td>540</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer  answer_number  \\\n",
       "0  Janet’s ducks lay 16 eggs per day. She eats th...   None             18   \n",
       "1  A robe takes 2 bolts of blue fiber and half th...   None              3   \n",
       "2  Josh decides to try flipping a house.  He buys...   None          70000   \n",
       "3  James decides to run 3 sprints 3 times a week....   None            540   \n",
       "4  Every day, Wendi feeds each of her chickens th...   None             20   \n",
       "\n",
       "  equation_solution language  \n",
       "0              None       en  \n",
       "1              None       en  \n",
       "2              None       en  \n",
       "3              None       en  \n",
       "4              None       en  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgsm_test.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Problem:\n",
      "Question: Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "Answer: Step-by-Step Answer: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
      "Answer Number: 11\n",
      "Equation_Solution: 5 + 6 = 11.\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "\n",
    "print(\"Sample Problem:\")\n",
    "print(\"Question:\", mgsm_train[sample_idx]['question'])\n",
    "print(\"Answer:\", mgsm_train[sample_idx]['answer'])\n",
    "print(\"Answer Number:\", mgsm_train[sample_idx]['answer_number'])\n",
    "print(\"Equation_Solution:\", mgsm_train[sample_idx]['equation_solution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Load evaluation data from Meta\n",
    "\n",
    "The evaluation data is publicly released by Meta and is available here: https://huggingface.co/datasets/meta-llama/Llama-3.2-1B-Instruct-evals\n",
    "\n",
    "We find here the following:\n",
    "- evaluation config\n",
    "- user prompts added in every language\n",
    "- parsed answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /data/students/ryan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2594b8e56244ca897b6e4bc64f91e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)_2024-09-23T17-23-09.030591.parquet.gzip:   0%|          | 0.00/1.45M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1a2e3638ed4971820f8eeb56b234fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating latest split:   0%|          | 0/2750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load token from config.json\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "hf_token = config[\"hf_token\"]\n",
    "login(hf_token)\n",
    "eval_dataset_FROM_META = load_dataset(\"meta-llama/Llama-3.2-1B-Instruct-evals\", \"Llama-3.2-1B-Instruct-evals__mgsm__details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_name</th>\n",
       "      <th>subtask_name</th>\n",
       "      <th>input_question</th>\n",
       "      <th>input_choice_list</th>\n",
       "      <th>input_final_prompts</th>\n",
       "      <th>input_correct_responses</th>\n",
       "      <th>output_prediction_text</th>\n",
       "      <th>output_parsed_answer</th>\n",
       "      <th>output_choice_completions</th>\n",
       "      <th>output_choice_negative_log_likelihoods</th>\n",
       "      <th>output_metrics</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>input_question_hash</th>\n",
       "      <th>input_final_prompts_hash</th>\n",
       "      <th>benchmark_label</th>\n",
       "      <th>eval_config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mgsm_chat</td>\n",
       "      <td>te</td>\n",
       "      <td>ఆండ్రూ న్యూజెర్సీ నుంచి రోచెస్టర్‌కు ఒక రోడ్డు...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nఈ...</td>\n",
       "      <td>[9, 9., 9.0, 9.0., 9.00, 9.00., 9, 9., 9.0, 9....</td>\n",
       "      <td>[రోచెస్టర్ నుంచి బస్సు ద్వారా ప్రయాణించడానికి ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'em': 0.0, 'em_maj1@1': 0.0, 'f1': 0.0, 'f1_m...</td>\n",
       "      <td>False</td>\n",
       "      <td>cd94ca91efc39a41e4c4c4bc0c05402edf876bb9e3b947...</td>\n",
       "      <td>[c08c78b2914e6099ee463c3e4f593bf5017c36c1ed754...</td>\n",
       "      <td>MGSM</td>\n",
       "      <td>{'max_gen_len': '2048', 'max_prompt_len': '614...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mgsm_chat</td>\n",
       "      <td>bn</td>\n",
       "      <td>কার্লের প্রিয় খাবার হল চিজ্‌। তিনি এই সপ্তাহে ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nএ...</td>\n",
       "      <td>[31, 31., 31.0, 31.0., 31.00, 31.00., 31, 31.,...</td>\n",
       "      <td>[সপ্তাহে তিনি 2*7=&lt;&lt;2*7=14&gt;&gt;14টি স্যান্ডউইচ খে...</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'em': 0.0, 'em_maj1@1': 0.0, 'f1': 0.0, 'f1_m...</td>\n",
       "      <td>False</td>\n",
       "      <td>6704115ad46deece36245043307151bd6fd83e02930329...</td>\n",
       "      <td>[1aec05a3e1d4a893e3b0d35624fb89159fc1c32561ec8...</td>\n",
       "      <td>MGSM</td>\n",
       "      <td>{'max_gen_len': '2048', 'max_prompt_len': '614...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mgsm_chat</td>\n",
       "      <td>bn</td>\n",
       "      <td>জ্যানেটের কাছে 22টি সবুজ কলম ও 10টি হলুদ কলম আ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nএ...</td>\n",
       "      <td>[98, 98., 98.0, 98.0., 98.00, 98.00., 98, 98.,...</td>\n",
       "      <td>[জ্যানেটের কাছে সবুজ কলমের মোট সংখ্যা হল 22টি ...</td>\n",
       "      <td>360</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'em': 0.0, 'em_maj1@1': 0.0, 'f1': 0.0, 'f1_m...</td>\n",
       "      <td>False</td>\n",
       "      <td>c034cb29e28be89863d8c81696515eb46614beb50893ae...</td>\n",
       "      <td>[b5dc4fc9106d844acf8f278cb90244e5f226aa9043a2a...</td>\n",
       "      <td>MGSM</td>\n",
       "      <td>{'max_gen_len': '2048', 'max_prompt_len': '614...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mgsm_chat</td>\n",
       "      <td>bn</td>\n",
       "      <td>ব্রিনলি মিঃ বার্টের অঙ্কের ক্লাসে আছে। প্রত্যে...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nএ...</td>\n",
       "      <td>[98, 98., 98.0, 98.0., 98.00, 98.00., 98, 98.,...</td>\n",
       "      <td>[প্রথম পাঁচটি পরীক্ষার স্কোর যোগ করলে আমরা পাই...</td>\n",
       "      <td>353</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'em': 0.0, 'em_maj1@1': 0.0, 'f1': 0.0, 'f1_m...</td>\n",
       "      <td>False</td>\n",
       "      <td>0c7da335161864651f040a8c291e0e78071a221800dcd4...</td>\n",
       "      <td>[42d35a0e59b2dce67fa4f109447b0752cd28c92d5e570...</td>\n",
       "      <td>MGSM</td>\n",
       "      <td>{'max_gen_len': '2048', 'max_prompt_len': '614...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generative</td>\n",
       "      <td>mgsm_chat</td>\n",
       "      <td>bn</td>\n",
       "      <td>মাইকেল বাইক চালাতে ভালোবাসেন। তিনি এটি এক সপ্ত...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nএ...</td>\n",
       "      <td>[860, 860., 860.0, 860.0., 860.00, 860.00., 86...</td>\n",
       "      <td>[মাইকেল 5 বার বাইক চালান, তাই তিনি 5*25=&lt;&lt;5*25...</td>\n",
       "      <td>860</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'em': 1.0, 'em_maj1@1': 1.0, 'f1': 1.0, 'f1_m...</td>\n",
       "      <td>True</td>\n",
       "      <td>f11366127c3e5d1b93ddb37334135fca18618c47e5b47e...</td>\n",
       "      <td>[0540c4c88eef5b44aaa61d9152e58f02465331eca313c...</td>\n",
       "      <td>MGSM</td>\n",
       "      <td>{'max_gen_len': '2048', 'max_prompt_len': '614...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_type  task_name subtask_name  \\\n",
       "0  Generative  mgsm_chat           te   \n",
       "1  Generative  mgsm_chat           bn   \n",
       "2  Generative  mgsm_chat           bn   \n",
       "3  Generative  mgsm_chat           bn   \n",
       "4  Generative  mgsm_chat           bn   \n",
       "\n",
       "                                      input_question input_choice_list  \\\n",
       "0  ఆండ్రూ న్యూజెర్సీ నుంచి రోచెస్టర్‌కు ఒక రోడ్డు...              None   \n",
       "1  কার্লের প্রিয় খাবার হল চিজ্‌। তিনি এই সপ্তাহে ...              None   \n",
       "2  জ্যানেটের কাছে 22টি সবুজ কলম ও 10টি হলুদ কলম আ...              None   \n",
       "3  ব্রিনলি মিঃ বার্টের অঙ্কের ক্লাসে আছে। প্রত্যে...              None   \n",
       "4  মাইকেল বাইক চালাতে ভালোবাসেন। তিনি এটি এক সপ্ত...              None   \n",
       "\n",
       "                                 input_final_prompts  \\\n",
       "0  [<|start_header_id|>user<|end_header_id|>\\n\\nఈ...   \n",
       "1  [<|start_header_id|>user<|end_header_id|>\\n\\nএ...   \n",
       "2  [<|start_header_id|>user<|end_header_id|>\\n\\nএ...   \n",
       "3  [<|start_header_id|>user<|end_header_id|>\\n\\nএ...   \n",
       "4  [<|start_header_id|>user<|end_header_id|>\\n\\nএ...   \n",
       "\n",
       "                             input_correct_responses  \\\n",
       "0  [9, 9., 9.0, 9.0., 9.00, 9.00., 9, 9., 9.0, 9....   \n",
       "1  [31, 31., 31.0, 31.0., 31.00, 31.00., 31, 31.,...   \n",
       "2  [98, 98., 98.0, 98.0., 98.00, 98.00., 98, 98.,...   \n",
       "3  [98, 98., 98.0, 98.0., 98.00, 98.00., 98, 98.,...   \n",
       "4  [860, 860., 860.0, 860.0., 860.00, 860.00., 86...   \n",
       "\n",
       "                              output_prediction_text output_parsed_answer  \\\n",
       "0  [రోచెస్టర్ నుంచి బస్సు ద్వారా ప్రయాణించడానికి ...                  4.5   \n",
       "1  [সপ্তাহে তিনি 2*7=<<2*7=14>>14টি স্যান্ডউইচ খে...                   25   \n",
       "2  [জ্যানেটের কাছে সবুজ কলমের মোট সংখ্যা হল 22টি ...                  360   \n",
       "3  [প্রথম পাঁচটি পরীক্ষার স্কোর যোগ করলে আমরা পাই...                  353   \n",
       "4  [মাইকেল 5 বার বাইক চালান, তাই তিনি 5*25=<<5*25...                  860   \n",
       "\n",
       "  output_choice_completions output_choice_negative_log_likelihoods  \\\n",
       "0                      None                                   None   \n",
       "1                      None                                   None   \n",
       "2                      None                                   None   \n",
       "3                      None                                   None   \n",
       "4                      None                                   None   \n",
       "\n",
       "                                      output_metrics  is_correct  \\\n",
       "0  {'em': 0.0, 'em_maj1@1': 0.0, 'f1': 0.0, 'f1_m...       False   \n",
       "1  {'em': 0.0, 'em_maj1@1': 0.0, 'f1': 0.0, 'f1_m...       False   \n",
       "2  {'em': 0.0, 'em_maj1@1': 0.0, 'f1': 0.0, 'f1_m...       False   \n",
       "3  {'em': 0.0, 'em_maj1@1': 0.0, 'f1': 0.0, 'f1_m...       False   \n",
       "4  {'em': 1.0, 'em_maj1@1': 1.0, 'f1': 1.0, 'f1_m...        True   \n",
       "\n",
       "                                 input_question_hash  \\\n",
       "0  cd94ca91efc39a41e4c4c4bc0c05402edf876bb9e3b947...   \n",
       "1  6704115ad46deece36245043307151bd6fd83e02930329...   \n",
       "2  c034cb29e28be89863d8c81696515eb46614beb50893ae...   \n",
       "3  0c7da335161864651f040a8c291e0e78071a221800dcd4...   \n",
       "4  f11366127c3e5d1b93ddb37334135fca18618c47e5b47e...   \n",
       "\n",
       "                            input_final_prompts_hash benchmark_label  \\\n",
       "0  [c08c78b2914e6099ee463c3e4f593bf5017c36c1ed754...            MGSM   \n",
       "1  [1aec05a3e1d4a893e3b0d35624fb89159fc1c32561ec8...            MGSM   \n",
       "2  [b5dc4fc9106d844acf8f278cb90244e5f226aa9043a2a...            MGSM   \n",
       "3  [42d35a0e59b2dce67fa4f109447b0752cd28c92d5e570...            MGSM   \n",
       "4  [0540c4c88eef5b44aaa61d9152e58f02465331eca313c...            MGSM   \n",
       "\n",
       "                                         eval_config  \n",
       "0  {'max_gen_len': '2048', 'max_prompt_len': '614...  \n",
       "1  {'max_gen_len': '2048', 'max_prompt_len': '614...  \n",
       "2  {'max_gen_len': '2048', 'max_prompt_len': '614...  \n",
       "3  {'max_gen_len': '2048', 'max_prompt_len': '614...  \n",
       "4  {'max_gen_len': '2048', 'max_prompt_len': '614...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset_FROM_META_df = eval_dataset_FROM_META['latest'].to_pandas()\n",
    "eval_dataset_FROM_META_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_gen_len': '2048',\n",
       " 'max_prompt_len': '6144',\n",
       " 'num_few_shot': '0',\n",
       " 'num_generations': '1',\n",
       " 'prompt_fn': \"functools.partial(<function jinja_dialog_format at 0x7f0d7e4c0d30>, template={'prompt': '{{ native_prompt }}\\\\n\\\\n{{ input }}', 'answer': '{{ target }}'}, append_gen_prefix=False)\",\n",
       " 'return_logprobs': 'false',\n",
       " 'seed': '42',\n",
       " 'temperature': '0.0',\n",
       " 'top_k': '0',\n",
       " 'top_p': '0'}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check META's eval_config\n",
    "eval_dataset_FROM_META_df['eval_config'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config = {\n",
    "    'max_gen_len': 2048,\n",
    "    'max_prompt_len': 6144,\n",
    "    'num_few_shot': 0,\n",
    "    'num_generations': 1,\n",
    "    # 'prompt_fn': functools.partial(jinja_dialog_format, template={'prompt': '{{ native_prompt }}\\\\n\\\\n{{ input }}', 'answer': '{{ target }}'}, append_gen_prefix=False),\n",
    "    'return_logprobs': False,\n",
    "    'seed': 42,\n",
    "    'temperature': 0.0,\n",
    "    'top_k': 0,\n",
    "    'top_p': 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "torch.manual_seed(eval_config['seed'])\n",
    "random.seed(eval_config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subtask_name\n",
       "te    250\n",
       "bn    250\n",
       "de    250\n",
       "th    250\n",
       "en    250\n",
       "zh    250\n",
       "fr    250\n",
       "ja    250\n",
       "ru    250\n",
       "es    250\n",
       "sw    250\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset_FROM_META_df[\"subtask_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Identify user prompts per language\n",
    "\n",
    "We add the user prompts used by Meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Solve this math problem. Give the reasoning steps before giving the final answer on the last line by itself in the format of \"Answer:\". Do not add anything other than the integer answer after \"Answer:\".\n",
      "\n",
      "Tracy used a piece of wire 4 feet long to support tomato plants in the garden. The wire was cut into pieces 6 inches long. How many pieces did she obtain?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "']\n"
     ]
    }
   ],
   "source": [
    "# check input_final_prompt for subtask_name = en\n",
    "filter = eval_dataset_FROM_META_df[\"subtask_name\"] == 'en'\n",
    "input_prompt = eval_dataset_FROM_META_df[filter]['input_final_prompts'].iloc[0]\n",
    "input_prompt = r\"{}\".format(input_prompt).replace(\"\\\\n\", \"\\n\") # convert prompt to raw string\n",
    "\n",
    "print(input_prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Solve this math problem. Give the reasoning steps before giving the final answer on the last line by itself in the format of \"Answer:\". Do not add anything other than the integer answer after \"Answer:\".\n",
      "\n",
      "Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_header = \"<|start_header_id|>user<|end_header_id|>\"\n",
    "assistant_header = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "\n",
    "user_prompts = {\n",
    "    \"en\": 'Solve this math problem. Give the reasoning steps before giving the final answer on the last line by itself in the format of \"Answer:\". Do not add anything other than the integer answer after \"Answer:\".',\n",
    "    \"te\": 'ఈ గణిత సమస్యను పరిష్కరించండి. చివరి సమాధానాన్ని ఇవ్వదానికి ముందు తర్కాత్మక అదుగులను ఇవ్వండి. చివరి పంక్తిలో మాత్రమే \"సమాధానం:\" అనే ఆకారంలో చివరి సమాధానాద్ని ఇవ్వండి సమాధానం: తర్వాత పూర్ణాంక సమాధానానికి తప్పించి ఎదేనా చేర్చవద్దు.',\n",
    "    \"bn\": 'এই গণিতের সমস্যাটি সমাধান করুন। চূড়ান্ত উত্তর দেওয়ার আগে যুক্তিসম্পন্ন পদক্ষেপ প্রদান করুন। চূড়ান্ত উত্তরটি একক সংখ্যা হিসাবে \"উত্তর:\" এর পরে শেষ লাইনে দিন। \"উত্তর:\" এর পরে অন্য কিছু যুক্ত করবেন না।.',\n",
    "    \"de\": 'Löse dieses Mathematikproblem. Gib die Schritte zur Begründung an, bevor du die endgültige Antwort in der letzten Zeile alleine im Format \"Antwort:\" gibst. Füge nichts anderes als die ganzzahlige Antwort nach \"Antwort:\" hinzu.',\n",
    "    \"th\": 'แก้ปัญหาคณิตศาสตร์นี้ ให้ให้ขั้นตอนการใช้เหตุผลก่อนที่จะให้คำตอบสุดท้ายในบรรทัดสุดท้ายโดยอยู่ในรูปแบบ \"คำตอบ:\" ไม่ควรเพิ่มอะไรนอกจากคำตอบที่เป็นจำนวนเต็มหลังจาก \"คำตอบ:\"',\n",
    "    \"zh\": '解决这个数学问题。在最后一行给出答案前，请提供推理步骤。最后一行应该以 \"答案: \" 的形式独立给出答案。在 \"答案：\" 后不要添加除整数答案之外的任何内容。',\n",
    "    \"fr\": 'Résolvez ce problème de mathématiques. Donnez les étapes de raisonnement avant de fournir la réponse finale sur la dernière ligne elle-même dans le format de \"Réponse:\". N\\'ajoutez rien d\\'autre que la réponse entière après \"Réponse:\".',\n",
    "    \"ja\": 'の数学の問題を解いてください。最終的な答えを出す前に、解答の推論過程を記述してください。そして最後の行には \"答え:\" の形式で答えを記述し、その後には整数の答え以外何も追加しないでください。',\n",
    "    \"ru\": 'Решите эту математическую задачу. Объясните шаги рассуждения перед тем, как дать окончательный ответ в последней строке сам по себе в формате \"Ответ:\". Не добавляйте ничего, кроме целочисленного ответа после \"Ответ:\".',\n",
    "    \"es\": 'Resuelve este problema matemático. Proporciona los pasos de razonamiento antes de dar la respuesta final en la última línea por sí misma en el formato de \"Respuesta:\". No añadas nada más que la respuesta entera después de \"Respuesta:\".',\n",
    "    \"sw\": 'Suluhisha tatizo hili la hesabu. Toa hatua za mantiki kabla ya kutoa jibu la mwisho kwenye mstari wa mwisho peke yake katika muundo wa \"Jibu:\". Usiongeze chochote kingine isipokuwa jibu la integer baada ya \"Jibu:\".'    \n",
    "}\n",
    "\n",
    "answer_translations = {\n",
    "    \"en\": \"Answer:\",\n",
    "    \"te\": \"సమాధానం:\",\n",
    "    \"bn\": \"উত্তর:\",\n",
    "    \"de\": \"Antwort:\",\n",
    "    \"th\": \"คำตอบ:\",\n",
    "    \"zh\": \"答案: \",\n",
    "    \"fr\": \"Réponse:\",\n",
    "    \"ja\": \"答え:\",\n",
    "    \"ru\": \"Ответ:\",\n",
    "    \"es\": \"Respuesta:\",\n",
    "    \"sw\": \"Jibu:\"\n",
    "}\n",
    "\n",
    "# sample prompt for an English question\n",
    "sample_idx = 0\n",
    "question = mgsm_test[sample_idx]['question']\n",
    "language = mgsm_test[sample_idx]['language']\n",
    "sample_prompt = user_header + \"\\n\\n\" + user_prompts[language] + \"\\n\\n\" + question + \"<|eot_id|>\" + assistant_header + \"\\n\\n\"\n",
    "print(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined in the cell above: user_header, assistant_header, user_prompts\n",
    "def add_input_prompt(question: str, language: str) -> str:\n",
    "    \"\"\"\"\n",
    "    question_features contains: \n",
    "        question\t\n",
    "        answer\t\n",
    "        answer_number\t\n",
    "        equation_solution\t\n",
    "        language\n",
    "    \"\"\"\n",
    "\n",
    "    return user_header + \"\\n\\n\" + user_prompts[language] + \"\\n\\n\" + question + \"<|eot_id|>\" + assistant_header + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL: Fine-tune model on MGSM training data\n",
    "\n",
    "TO FIX:\n",
    "- check MGSM for any fine tuning details\n",
    "- add prompt fn\n",
    "- modify tokenizer function\n",
    "- separate train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'peft'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[311], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     BitsAndBytesConfig,\n\u001b[1;32m      3\u001b[0m     TrainingArguments,\n\u001b[1;32m      4\u001b[0m     pipeline,\n\u001b[1;32m      5\u001b[0m     logging,\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraConfig\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'peft'"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = mgsm_train.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create parser for the model's final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Gemma's GSM8k Evaluation Code: https://github.com/google-deepmind/gemma/blob/main/colabs/gsm8k_eval.ipynb\n",
    "\n",
    "def find_numbers(x: str) -> list[str]:\n",
    "  \"\"\"Finds all numbers in a string.\"\"\"\n",
    "  # Search for number, possibly negative (hyphen), with thousand separators\n",
    "  # (comma), and with a decimal point (period inbetween digits).\n",
    "  numbers = re.compile(\n",
    "      r'-?[\\d,]*\\.?\\d+',\n",
    "      re.MULTILINE | re.DOTALL | re.IGNORECASE,\n",
    "  ).findall(x)\n",
    "  return numbers\n",
    "\n",
    "\n",
    "def find_number(x: str,\n",
    "                answer_delimiter: str = 'Answer:') -> str:\n",
    "  \"\"\"Finds the most relevant number in a string.\"\"\"\n",
    "  # If model uses the answer delimiter, then select the first number following\n",
    "  # that format.\n",
    "  if answer_delimiter in x:\n",
    "    answer = x.split(answer_delimiter)[-1]\n",
    "    numbers = find_numbers(answer)\n",
    "    # print(\"Found delimiter!\")\n",
    "    # print(numbers)\n",
    "\n",
    "    if numbers:\n",
    "      return numbers[0]\n",
    "\n",
    "  # In general, select the last number in the string.\n",
    "  numbers = find_numbers(x)\n",
    "  # print(numbers)\n",
    "\n",
    "  if numbers:\n",
    "    return numbers[-1]\n",
    "  return ''\n",
    "\n",
    "\n",
    "def maybe_remove_comma(x: str) -> str:\n",
    "  # Example: 5,600 -> 5600\n",
    "  return x.replace(',', '')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_config = {\n",
    "    'max_new_tokens': eval_config['max_gen_len'],\n",
    "    'num_return_sequences': eval_config['num_generations'],\n",
    "    'output_scores': eval_config['return_logprobs'],\n",
    "    'pad_token_id': tokenizer.eos_token_id,\n",
    "    'do_sample': False,  # since temperature, top_k, top_p are 0\n",
    "    'top_p': None,\n",
    "    'temperature': None,\n",
    "    'top_k': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the profit, first calculate the increased value of the house after repairs:\n",
      "\n",
      "$80,000 + ($50,000 x 1.5) = $80,000 + $75,000 = $155,000\n",
      "\n",
      "Then, subtract the original purchase price from the increased value to find the profit:\n",
      "\n",
      "$155,000 - $80,000 = $75,000\n",
      "\n",
      "Answer: $75,000\n"
     ]
    }
   ],
   "source": [
    "# Generate a sample inference\n",
    "sample_idx = 2\n",
    "\n",
    "input_prompt = add_input_prompt(mgsm_test[sample_idx]['question'], mgsm_test[sample_idx]['language'])\n",
    "input_tokenized = tokenizer(input_prompt, return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "output = model.generate(**input_tokenized, \n",
    "                        **generate_config\n",
    "                        )\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# splice output_text after \"assistant\"\n",
    "assistant_idx = output_text.find(\"assistant\\n\\n\")\n",
    "output_text = output_text[assistant_idx + len(\"assistant\\n\\n\"):]\n",
    "\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Answer: 75000\n"
     ]
    }
   ],
   "source": [
    "answer_delimiter = answer_translations[mgsm_test[sample_idx]['language']]\n",
    "output_numerical_answer = maybe_remove_comma(find_number(output_text, answer_delimiter))\n",
    "\n",
    "print(\"Numerical Answer:\", output_numerical_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [2:28:59<00:00, 81.27s/it] \n"
     ]
    }
   ],
   "source": [
    "# Parameters for batch processing\n",
    "loader_config = {'batch_size': 25,\n",
    "                 'num_workers': 4, \n",
    "                 'prefetch_factor': 2,\n",
    "                 'shuffle': False}\n",
    "\n",
    "# mgsm_test = mgsm_test.remove_columns([\"answer\", \"equation_solution\"]) ## COMMENT OUT IF DATALOADER FAILS\n",
    "\n",
    "# Create a DataLoader for the dataset\n",
    "test_data_loader = DataLoader(mgsm_test, **loader_config)\n",
    "\n",
    "# Initializa a dictionary to store the results\n",
    "results_mgsm = {'question': mgsm_test['question'], \n",
    "                'language': mgsm_test['language'], \n",
    "                'ground_truth': mgsm_test['answer_number'], \n",
    "                'generated_answer': []}\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for batch_samples in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "\n",
    "    # Add input prompt to the batch problems\n",
    "    batch_problems = [add_input_prompt(question, language) for question, language in zip(batch_samples['question'], batch_samples['language'])]\n",
    "    \n",
    "    # Tokenize the input problems\n",
    "    inputs = tokenizer(batch_problems, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Generate outputs from the model for the entire batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **generate_config)\n",
    "\n",
    "    # Get numerical answer from output texts\n",
    "    output_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    numerical_answers = [maybe_remove_comma(find_number(output_text, answer_translations[language])) for output_text, language in zip(output_texts, batch_samples['language'])]\n",
    "\n",
    "    # Add the numerical answers to the results dictionary\n",
    "    results_mgsm['generated_answer'].extend(numerical_answers)\n",
    "\n",
    "# Create a directory to store the results\n",
    "output_dir = \"outputs\"\n",
    "results_var_name = \"results_mgsm\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the results to a file\n",
    "results_file = os.path.join(output_dir, f\"{results_var_name}.json\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(globals()[results_var_name], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_mgsm['question'] = results_mgsm['question'][:75]\n",
    "# results_mgsm['ground_truth'] = results_mgsm['ground_truth'][:75]\n",
    "# results_mgsm['language'] = results_mgsm['language'][:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the results to a file\n",
    "# results_file = os.path.join(output_dir, f\"{results_var_name}.json\")\n",
    "# with open(results_file, \"w\") as f:\n",
    "#     json.dump(globals()[results_var_name], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate score\n",
    "\n",
    "We calculate the average exact match (maj@1) scores over all eleven languages in the MGSM dataset. \\\n",
    "Reference: https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/eval_details.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in generated answers: 2\n"
     ]
    }
   ],
   "source": [
    "# Check null values in generated answers\n",
    "null_values = results_mgsm['generated_answer'].count('')\n",
    "print(f\"Number of null values in generated answers: {null_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of null values in generated answers: [2491, 2586]\n"
     ]
    }
   ],
   "source": [
    "# Find index in results_mgsm generated answer with null values\n",
    "null_indices = [idx for idx, value in enumerate(results_mgsm['generated_answer']) if value == '']\n",
    "print(f\"Indices of null values in generated answers: {null_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'language', 'ground_truth', 'generated_answer'])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mgsm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "గ్రెగ్ వద్ద రిమైండర్ వలే రోజుకు మూడుసార్లు మోగే ఒక అలారమ్ ఉంది, అలారం మోగడం మొదలైతే, గ్రేగ్ దానిని ఆపేంత వరకు రింగ్ అవుతూనే ఉంటుంది. ఇవాళ అది మొదటిసారి మోగినప్పుడు, అది నాలుగుసార్లు రింగ్ అయింది. రెండోసారి అది మోగినప్పుడు, అది మొదటిసారి కంటే మూడురెట్లు ఎక్కువగా రింగ్ అయింది. మూడోసారి అది రెండోసారి అంతసేపు రింగ్ అయింది. మొత్తం మీద అలారం ఎన్నిసార్లు మోగింది?\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(results_mgsm['question'][null_indices[1]])\n",
    "print(results_mgsm['ground_truth'][null_indices[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>language</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>en</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8712.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>en</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>en</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>en</td>\n",
       "      <td>540.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>en</td>\n",
       "      <td>20.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>ఒక అక్వైరియంలో 4 నత్తలు మరియు మరో అక్వైరియంలో ...</td>\n",
       "      <td>te</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>జీన్స్ మేకప్ ఆర్టిస్ట్ ప్రతి గంటకు $250 ఛార్జ్...</td>\n",
       "      <td>te</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>ఇసాబెల్లా తన చిన్న సోదరి పుట్టినరోజు పార్టీ కొ...</td>\n",
       "      <td>te</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>ఒక చెఫ్ 4 బస్తాల ఉల్లిపాయలను కొనుగోలు చేశాడు. ...</td>\n",
       "      <td>te</td>\n",
       "      <td>300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>సోమవారం నాడు, స్యూ ఆమె సోదరితో పోలిస్తే 4 రెట్...</td>\n",
       "      <td>te</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2234 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question language  \\\n",
       "0     Janet’s ducks lay 16 eggs per day. She eats th...       en   \n",
       "1     A robe takes 2 bolts of blue fiber and half th...       en   \n",
       "2     Josh decides to try flipping a house.  He buys...       en   \n",
       "3     James decides to run 3 sprints 3 times a week....       en   \n",
       "4     Every day, Wendi feeds each of her chickens th...       en   \n",
       "...                                                 ...      ...   \n",
       "2745  ఒక అక్వైరియంలో 4 నత్తలు మరియు మరో అక్వైరియంలో ...       te   \n",
       "2746  జీన్స్ మేకప్ ఆర్టిస్ట్ ప్రతి గంటకు $250 ఛార్జ్...       te   \n",
       "2747  ఇసాబెల్లా తన చిన్న సోదరి పుట్టినరోజు పార్టీ కొ...       te   \n",
       "2748  ఒక చెఫ్ 4 బస్తాల ఉల్లిపాయలను కొనుగోలు చేశాడు. ...       te   \n",
       "2749  సోమవారం నాడు, స్యూ ఆమె సోదరితో పోలిస్తే 4 రెట్...       te   \n",
       "\n",
       "      ground_truth  generated_answer  correct  \n",
       "0             18.0            8712.0    False  \n",
       "1              3.0               6.0    False  \n",
       "2          70000.0           75000.0    False  \n",
       "3            540.0             180.0    False  \n",
       "4             20.0             800.0    False  \n",
       "...            ...               ...      ...  \n",
       "2745           7.0               4.0    False  \n",
       "2746       27000.0             250.0    False  \n",
       "2747          32.0              12.0    False  \n",
       "2748         300.0               4.0    False  \n",
       "2749        5600.0               4.0    False  \n",
       "\n",
       "[2234 rows x 5 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df['correct'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta's Overall Accuracy: 0.24472727272727274\n",
      "Personal Overall Accuracy: 0.18763636363636363\n",
      "\n",
      "\n",
      "   Language  Meta Score  Personal Score  Language Supported\n",
      "0        bn       0.144           0.144               False\n",
      "1        de       0.272           0.240                True\n",
      "2        en       0.420           0.408                True\n",
      "3        es       0.352           0.248                True\n",
      "4        fr       0.264           0.212                True\n",
      "5        ja       0.180           0.148               False\n",
      "6        ru       0.272           0.244               False\n",
      "7        sw       0.184           0.020               False\n",
      "8        te       0.112           0.016               False\n",
      "9        th       0.228           0.204                True\n",
      "10       zh       0.264           0.180               False\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"outputs\"\n",
    "results_var_name = \"results_mgsm\"\n",
    "\n",
    "# Load the results from the json file and convert to pandas DataFrame\n",
    "results_file = os.path.join(output_dir, f\"{results_var_name}.json\")\n",
    "results_df = pd.read_json(results_file)\n",
    "\n",
    "# Convert ground_truth and generated_answer columns to float\n",
    "results_df['ground_truth'] = results_df['ground_truth'].astype(float)\n",
    "# results_df['generated_answer'] = results_df['generated_answer'].astype(float)\n",
    "results_df['generated_answer'] = pd.to_numeric(results_df['generated_answer'], errors='coerce')\n",
    "    # coerce will convert the invalid parsing to NaN\n",
    "\n",
    "\n",
    "# Compare the generated answers with the ground truth answers\n",
    "results_df['correct'] = results_df['ground_truth'] == results_df['generated_answer']\n",
    "\n",
    "# Get accuracy per language then get average accuracy\n",
    "accuracy_per_language = results_df.groupby('language')['correct'].mean()\n",
    "overall_accuracy = accuracy_per_language.mean()\n",
    "\n",
    "# Get Meta's accuracy\n",
    "meta_accuracy = eval_dataset_FROM_META_df.groupby('subtask_name')['is_correct'].mean()\n",
    "meta_accuracy_overall = meta_accuracy.mean()\n",
    "print(\"Meta's Overall Accuracy:\", meta_accuracy_overall)\n",
    "print(\"Personal Overall Accuracy:\", overall_accuracy)\n",
    "\n",
    "\n",
    "# Check if the language is supported (see https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/blob/main/README.md?code=true)\n",
    "lang_supported = ['en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th']\n",
    "is_supported = [lang in lang_supported for lang in accuracy_per_language.index]\n",
    "\n",
    "# Compare Meta and personal evaluation results\n",
    "eval_scores_df = pd.DataFrame({\n",
    "    'Language': meta_accuracy.index,\n",
    "    'Meta Score': meta_accuracy.values,\n",
    "    'Personal Score': accuracy_per_language.values,\n",
    "    'Language Supported': is_supported\n",
    "})\n",
    "\n",
    "print('\\n')\n",
    "print(eval_scores_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai231-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
