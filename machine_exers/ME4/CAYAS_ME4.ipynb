{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 1B Evaluation\n",
    "Ryan Roi Cayas\\\n",
    "2022-22085\n",
    "\n",
    "In this notebook, we replicate the published scores of the Llama 3.2 1B on the MGSM dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load libraries and set-up CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast\n",
    "from datasets import load_dataset, concatenate_datasets # Huggingface datasets (https://huggingface.co/docs/datasets/)\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "# Set-up CUDA device\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "# use a specific GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Use GPU for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print the device being used\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check the GPU name\n",
    "if device.type == 'cuda':\n",
    "    gpu_name = torch.cuda.get_device_name(0)  # 0 because CUDA_VISIBLE_DEVICES=4 means GPU 4 is now 0\n",
    "    print(\"Using GPU:\", gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the pre-trained tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to model and tokenizer\n",
    "model_dir = \"../../../../../llm/llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_dir)\n",
    "model = LlamaForCausalLM.from_pretrained(model_dir)\n",
    "\n",
    "# Set the eos_token as the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load the MGSM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading datasets: 100%|██████████| 11/11 [00:32<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'answer_number', 'equation_solution', 'language'],\n",
      "    num_rows: 88\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'answer_number', 'equation_solution', 'language'],\n",
      "    num_rows: 2750\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Languages: English, Spanish, French, German, Russian, Chinese, Japanese, Thai, Swahili, Bengali, Telugu\n",
    "languages = [\"en\",\"es\",\"fr\",\"de\",\"ru\",\"zh\",\"ja\",\"th\",\"sw\",\"bn\",\"te\"]\n",
    "\n",
    "# Empty list to store datasets with added 'language' feature\n",
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "# Load the datasets and add the 'language' feature\n",
    "for lang in tqdm(languages, desc=\"Loading datasets\"):\n",
    "    # Load train and test datasets for the language\n",
    "    train = load_dataset(\"juletxara/mgsm\", lang, split=\"train\")\n",
    "    test = load_dataset(\"juletxara/mgsm\", lang, split=\"test\")\n",
    "    \n",
    "    # Add the 'language' feature to both train and test sets\n",
    "    train = train.add_column(\"language\", [lang] * len(train))\n",
    "    test = test.add_column(\"language\", [lang] * len(test))\n",
    "    \n",
    "    # Append the datasets with the 'language' feature to the lists\n",
    "    train_datasets.append(train)\n",
    "    test_datasets.append(test)\n",
    "\n",
    "# Concatenate datasets from all languages into a single train and test dataset\n",
    "mgsm_train = concatenate_datasets(train_datasets)\n",
    "mgsm_test = concatenate_datasets(test_datasets)\n",
    "\n",
    "# Verify the structure\n",
    "print(mgsm_train)\n",
    "print(mgsm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>equation_solution</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question: Roger has 5 tennis balls. He buys 2 ...</td>\n",
       "      <td>Step-by-Step Answer: Roger started with 5 ball...</td>\n",
       "      <td>11</td>\n",
       "      <td>5 + 6 = 11.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question: There were nine computers in the ser...</td>\n",
       "      <td>Step-by-Step Answer: There are 4 days from mon...</td>\n",
       "      <td>29</td>\n",
       "      <td>4 * 5 = 20. 9 + 20 = 29.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: Leah had 32 chocolates and her siste...</td>\n",
       "      <td>Step-by-Step Answer: Leah had 32 chocolates an...</td>\n",
       "      <td>39</td>\n",
       "      <td>32 + 42 = 74. 74 - 35 = 39.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Question: Shawn has five toys. For Christmas, ...</td>\n",
       "      <td>Step-by-Step Answer: He has 5 toys. He got 2 f...</td>\n",
       "      <td>9</td>\n",
       "      <td>5 + 2 = 7. 7 + 2 = 9.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question: Michael had 58 golf balls. On tuesda...</td>\n",
       "      <td>Step-by-Step Answer: Michael started with 58 g...</td>\n",
       "      <td>33</td>\n",
       "      <td>58 - 23 = 35. 35 - 2 = 33.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Question: Roger has 5 tennis balls. He buys 2 ...   \n",
       "1  Question: There were nine computers in the ser...   \n",
       "2  Question: Leah had 32 chocolates and her siste...   \n",
       "3  Question: Shawn has five toys. For Christmas, ...   \n",
       "4  Question: Michael had 58 golf balls. On tuesda...   \n",
       "\n",
       "                                              answer  answer_number  \\\n",
       "0  Step-by-Step Answer: Roger started with 5 ball...             11   \n",
       "1  Step-by-Step Answer: There are 4 days from mon...             29   \n",
       "2  Step-by-Step Answer: Leah had 32 chocolates an...             39   \n",
       "3  Step-by-Step Answer: He has 5 toys. He got 2 f...              9   \n",
       "4  Step-by-Step Answer: Michael started with 58 g...             33   \n",
       "\n",
       "             equation_solution language  \n",
       "0                  5 + 6 = 11.       en  \n",
       "1     4 * 5 = 20. 9 + 20 = 29.       en  \n",
       "2  32 + 42 = 74. 74 - 35 = 39.       en  \n",
       "3        5 + 2 = 7. 7 + 2 = 9.       en  \n",
       "4   58 - 23 = 35. 35 - 2 = 33.       en  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgsm_train.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_number</th>\n",
       "      <th>equation_solution</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>None</td>\n",
       "      <td>70000</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>None</td>\n",
       "      <td>540</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer  answer_number  \\\n",
       "0  Janet’s ducks lay 16 eggs per day. She eats th...   None             18   \n",
       "1  A robe takes 2 bolts of blue fiber and half th...   None              3   \n",
       "2  Josh decides to try flipping a house.  He buys...   None          70000   \n",
       "3  James decides to run 3 sprints 3 times a week....   None            540   \n",
       "4  Every day, Wendi feeds each of her chickens th...   None             20   \n",
       "\n",
       "  equation_solution language  \n",
       "0              None       en  \n",
       "1              None       en  \n",
       "2              None       en  \n",
       "3              None       en  \n",
       "4              None       en  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgsm_test.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Problem:\n",
      "Question: Question: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
      "Answer: Step-by-Step Answer: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
      "Answer Number: 11\n",
      "Equation_Solution: 5 + 6 = 11.\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "\n",
    "print(\"Sample Problem:\")\n",
    "print(\"Question:\", mgsm_train[sample_idx]['question'])\n",
    "print(\"Answer:\", mgsm_train[sample_idx]['answer'])\n",
    "print(\"Answer Number:\", mgsm_train[sample_idx]['answer_number'])\n",
    "print(\"Equation_Solution:\", mgsm_train[sample_idx]['equation_solution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Load evaluation data from Meta\n",
    "\n",
    "The evaluation data is publicly released by Meta and is available here: https://huggingface.co/datasets/meta-llama/Llama-3.2-1B-Instruct-evals\n",
    "\n",
    "We mainly use this to identify the additional instructions and prompts used by Meta to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /data/students/ryan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Load token from config.json\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "hf_token = config[\"hf_token\"]\n",
    "login(hf_token)\n",
    "eval_dataset_FROM_META = load_dataset(\"meta-llama/Llama-3.2-1B-Instruct-evals\", \"Llama-3.2-1B-Instruct-evals__mgsm__details\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai231-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
