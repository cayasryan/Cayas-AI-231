{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 1B Evaluation\n",
    "Ryan Roi Cayas\\\n",
    "2022-22085\n",
    "\n",
    "In this notebook, we replicate the published scores of the Llama 3.2 1B on the MATH dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load libraries and set-up CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast\n",
    "from datasets import load_dataset, concatenate_datasets # Huggingface datasets (https://huggingface.co/docs/datasets/)\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "# Set-up CUDA device\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "# use a specific GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "# Use GPU for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print the device being used\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check the GPU name\n",
    "if device.type == 'cuda':\n",
    "    gpu_name = torch.cuda.get_device_name(0)  # 0 because CUDA_VISIBLE_DEVICES=4 means GPU 4 is now 0\n",
    "    print(\"Using GPU:\", gpu_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the pre-trained tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to model and tokenizer\n",
    "model_dir = \"../../../../../../llm/llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_dir, padding_side=\"left\")\n",
    "model = LlamaForCausalLM.from_pretrained(model_dir)\n",
    "\n",
    "# Set the eos_token as the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load the MATH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many vertical asymptotes does the graph of...</td>\n",
       "      <td>Level 3</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>The denominator of the rational function facto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the positive difference between $120\\%...</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>One hundred twenty percent of 30 is $120\\cdot3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find $x$ such that $\\lceil x \\rceil + x = \\dfr...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>First, we note that $x$ must be positive, sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evaluate $i^5+i^{-25}+i^{45}$.</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>We have $i^5 = i^4\\cdot i = 1\\cdot (i) = i$.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If $2^8=4^x$, what is the value of $x$?</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>Rewrite $4$ as $2^2$ to find $4^x=2^{2x}$.  Si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             problem    level     type  \\\n",
       "0  How many vertical asymptotes does the graph of...  Level 3  Algebra   \n",
       "1  What is the positive difference between $120\\%...  Level 1  Algebra   \n",
       "2  Find $x$ such that $\\lceil x \\rceil + x = \\dfr...  Level 4  Algebra   \n",
       "3                     Evaluate $i^5+i^{-25}+i^{45}$.  Level 5  Algebra   \n",
       "4            If $2^8=4^x$, what is the value of $x$?  Level 1  Algebra   \n",
       "\n",
       "                                            solution  \n",
       "0  The denominator of the rational function facto...  \n",
       "1  One hundred twenty percent of 30 is $120\\cdot3...  \n",
       "2  First, we note that $x$ must be positive, sinc...  \n",
       "3  We have $i^5 = i^4\\cdot i = 1\\cdot (i) = i$.  ...  \n",
       "4  Rewrite $4$ as $2^2$ to find $4^x=2^{2x}$.  Si...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_dataset_test = load_dataset('competition_math', split='test')\n",
    "math_dataset_test.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>level</th>\n",
       "      <th>type</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many vertical asymptotes does the graph of...</td>\n",
       "      <td>Level 3</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>The denominator of the rational function facto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the positive difference between $120\\%...</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>One hundred twenty percent of 30 is $120\\cdot3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find $x$ such that $\\lceil x \\rceil + x = \\dfr...</td>\n",
       "      <td>Level 4</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>First, we note that $x$ must be positive, sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evaluate $i^5+i^{-25}+i^{45}$.</td>\n",
       "      <td>Level 5</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>We have $i^5 = i^4\\cdot i = 1\\cdot (i) = i$.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If $2^8=4^x$, what is the value of $x$?</td>\n",
       "      <td>Level 1</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>Rewrite $4$ as $2^2$ to find $4^x=2^{2x}$.  Si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             problem    level     type  \\\n",
       "0  How many vertical asymptotes does the graph of...  Level 3  Algebra   \n",
       "1  What is the positive difference between $120\\%...  Level 1  Algebra   \n",
       "2  Find $x$ such that $\\lceil x \\rceil + x = \\dfr...  Level 4  Algebra   \n",
       "3                     Evaluate $i^5+i^{-25}+i^{45}$.  Level 5  Algebra   \n",
       "4            If $2^8=4^x$, what is the value of $x$?  Level 1  Algebra   \n",
       "\n",
       "                                            solution  \n",
       "0  The denominator of the rational function facto...  \n",
       "1  One hundred twenty percent of 30 is $120\\cdot3...  \n",
       "2  First, we note that $x$ must be positive, sinc...  \n",
       "3  We have $i^5 = i^4\\cdot i = 1\\cdot (i) = i$.  ...  \n",
       "4  Rewrite $4$ as $2^2$ to find $4^x=2^{2x}$.  Si...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_dataset_train = load_dataset('competition_math', split='test')\n",
    "math_dataset_train.to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: How many vertical asymptotes does the graph of $y=\\frac{2}{x^2+x-6}$ have?\n",
      "Level: Level 3\n",
      "Type: Algebra\n",
      "Solution: The denominator of the rational function factors into $x^2+x-6=(x-2)(x+3)$. Since the numerator is always nonzero, there is a vertical asymptote whenever the denominator is $0$, which occurs for $x = 2$ and $x = -3$.  Therefore, the graph has $\\boxed{2}$ vertical asymptotes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem:\",math_dataset_test[0]['problem'])\n",
    "print(\"Level:\",math_dataset_test[0]['level'])\n",
    "print(\"Type:\",math_dataset_test[0]['type'])\n",
    "print(\"Solution:\",math_dataset_test[0]['solution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Load evaluation data from Meta\n",
    "\n",
    "The evaluation data is publicly released by Meta and is available here: https://huggingface.co/datasets/meta-llama/Llama-3.2-1B-Instruct-evals\n",
    "\n",
    "We find here the following:\n",
    "- evaluation config\n",
    "- full input prompts used by Meta\n",
    "- parsed answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /data/students/ryan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Load token from config.json\n",
    "with open(\"config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "hf_token = config[\"hf_token\"]\n",
    "login(hf_token)\n",
    "eval_dataset_FROM_META = load_dataset(\"meta-llama/Llama-3.2-1B-Instruct-evals\", \"Llama-3.2-1B-Instruct-evals__math__details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>task_name</th>\n",
       "      <th>subtask_name</th>\n",
       "      <th>input_question</th>\n",
       "      <th>input_choice_list</th>\n",
       "      <th>input_final_prompts</th>\n",
       "      <th>input_correct_responses</th>\n",
       "      <th>output_prediction_text</th>\n",
       "      <th>output_parsed_answer</th>\n",
       "      <th>output_choice_completions</th>\n",
       "      <th>output_choice_negative_log_likelihoods</th>\n",
       "      <th>output_metrics</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>input_question_hash</th>\n",
       "      <th>input_final_prompts_hash</th>\n",
       "      <th>benchmark_label</th>\n",
       "      <th>eval_config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generative</td>\n",
       "      <td>math_chat_new</td>\n",
       "      <td>None</td>\n",
       "      <td>Find the imaginary part of \\[(\\cos12^\\circ+i\\s...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nS...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[## Step 1: Express the given expression in po...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'correct_format': 1.0, 'em': 1.0, 'em_maj1@1'...</td>\n",
       "      <td>True</td>\n",
       "      <td>5a2e4b5ae809e4fe13e8e25fedadc00309a38c663a0872...</td>\n",
       "      <td>[adcde01feac66b5a5a928be8804031ffddcb481ef73e4...</td>\n",
       "      <td>MATH (4-shot, CoT)</td>\n",
       "      <td>{'max_gen_len': '5120', 'max_prompt_len': '307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generative</td>\n",
       "      <td>math_chat_new</td>\n",
       "      <td>None</td>\n",
       "      <td>What is the least, positive four-digit multipl...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nS...</td>\n",
       "      <td>[1001]</td>\n",
       "      <td>[## Step 1: Determine the smallest four-digit ...</td>\n",
       "      <td>1007</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'correct_format': 1.0, 'em': 0.0, 'em_maj1@1'...</td>\n",
       "      <td>False</td>\n",
       "      <td>05be5a24c13a7f03934ca04c01bd595e757234538b3118...</td>\n",
       "      <td>[97745be9a6acd60858e258a46fbd4946e2904dd320c6c...</td>\n",
       "      <td>MATH (4-shot, CoT)</td>\n",
       "      <td>{'max_gen_len': '5120', 'max_prompt_len': '307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generative</td>\n",
       "      <td>math_chat_new</td>\n",
       "      <td>None</td>\n",
       "      <td>What is $(1 + 2 \\cdot 3 \\cdot 4 \\cdot 5) \\div ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nS...</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[## Step 1: Calculate the product inside the p...</td>\n",
       "      <td>21.909...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'correct_format': 1.0, 'em': 0.0, 'em_maj1@1'...</td>\n",
       "      <td>False</td>\n",
       "      <td>fc91c2faca18e68429a3ad12d1edcaf5eaa84183506aaf...</td>\n",
       "      <td>[2a840b3673983db48b20ed473579b710ad1f111764425...</td>\n",
       "      <td>MATH (4-shot, CoT)</td>\n",
       "      <td>{'max_gen_len': '5120', 'max_prompt_len': '307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generative</td>\n",
       "      <td>math_chat_new</td>\n",
       "      <td>None</td>\n",
       "      <td>Two ropes, 18 meters in length and 24 meters i...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nS...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[## Step 1: Identify the key constraint\\nThe p...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'correct_format': 1.0, 'em': 0.0, 'em_maj1@1'...</td>\n",
       "      <td>False</td>\n",
       "      <td>9e87e5f82a292976ff7a0503c803bb2fcbb026b1954d59...</td>\n",
       "      <td>[c7952d5c97db4006ebe8fba59bf41c9caa6dc35c59590...</td>\n",
       "      <td>MATH (4-shot, CoT)</td>\n",
       "      <td>{'max_gen_len': '5120', 'max_prompt_len': '307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generative</td>\n",
       "      <td>math_chat_new</td>\n",
       "      <td>None</td>\n",
       "      <td>In the diagram below, lines $k$ and $\\ell$ are...</td>\n",
       "      <td>None</td>\n",
       "      <td>[&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nS...</td>\n",
       "      <td>[60]</td>\n",
       "      <td>[## Step 1:  The problem provides a diagram wi...</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'correct_format': 1.0, 'em': 0.0, 'em_maj1@1'...</td>\n",
       "      <td>False</td>\n",
       "      <td>30625ff210cf5a08933c65b91f4ff6b36fa1d03087ea1a...</td>\n",
       "      <td>[857c3d7d39e2cef68320fb00d5271b66676ba06244744...</td>\n",
       "      <td>MATH (4-shot, CoT)</td>\n",
       "      <td>{'max_gen_len': '5120', 'max_prompt_len': '307...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_type      task_name subtask_name  \\\n",
       "0  Generative  math_chat_new         None   \n",
       "1  Generative  math_chat_new         None   \n",
       "2  Generative  math_chat_new         None   \n",
       "3  Generative  math_chat_new         None   \n",
       "4  Generative  math_chat_new         None   \n",
       "\n",
       "                                      input_question input_choice_list  \\\n",
       "0  Find the imaginary part of \\[(\\cos12^\\circ+i\\s...              None   \n",
       "1  What is the least, positive four-digit multipl...              None   \n",
       "2  What is $(1 + 2 \\cdot 3 \\cdot 4 \\cdot 5) \\div ...              None   \n",
       "3  Two ropes, 18 meters in length and 24 meters i...              None   \n",
       "4  In the diagram below, lines $k$ and $\\ell$ are...              None   \n",
       "\n",
       "                                 input_final_prompts input_correct_responses  \\\n",
       "0  [<|start_header_id|>user<|end_header_id|>\\n\\nS...                     [0]   \n",
       "1  [<|start_header_id|>user<|end_header_id|>\\n\\nS...                  [1001]   \n",
       "2  [<|start_header_id|>user<|end_header_id|>\\n\\nS...                    [11]   \n",
       "3  [<|start_header_id|>user<|end_header_id|>\\n\\nS...                     [6]   \n",
       "4  [<|start_header_id|>user<|end_header_id|>\\n\\nS...                    [60]   \n",
       "\n",
       "                              output_prediction_text output_parsed_answer  \\\n",
       "0  [## Step 1: Express the given expression in po...                    0   \n",
       "1  [## Step 1: Determine the smallest four-digit ...                 1007   \n",
       "2  [## Step 1: Calculate the product inside the p...            21.909...   \n",
       "3  [## Step 1: Identify the key constraint\\nThe p...                    1   \n",
       "4  [## Step 1:  The problem provides a diagram wi...                   30   \n",
       "\n",
       "  output_choice_completions output_choice_negative_log_likelihoods  \\\n",
       "0                      None                                   None   \n",
       "1                      None                                   None   \n",
       "2                      None                                   None   \n",
       "3                      None                                   None   \n",
       "4                      None                                   None   \n",
       "\n",
       "                                      output_metrics  is_correct  \\\n",
       "0  {'correct_format': 1.0, 'em': 1.0, 'em_maj1@1'...        True   \n",
       "1  {'correct_format': 1.0, 'em': 0.0, 'em_maj1@1'...       False   \n",
       "2  {'correct_format': 1.0, 'em': 0.0, 'em_maj1@1'...       False   \n",
       "3  {'correct_format': 1.0, 'em': 0.0, 'em_maj1@1'...       False   \n",
       "4  {'correct_format': 1.0, 'em': 0.0, 'em_maj1@1'...       False   \n",
       "\n",
       "                                 input_question_hash  \\\n",
       "0  5a2e4b5ae809e4fe13e8e25fedadc00309a38c663a0872...   \n",
       "1  05be5a24c13a7f03934ca04c01bd595e757234538b3118...   \n",
       "2  fc91c2faca18e68429a3ad12d1edcaf5eaa84183506aaf...   \n",
       "3  9e87e5f82a292976ff7a0503c803bb2fcbb026b1954d59...   \n",
       "4  30625ff210cf5a08933c65b91f4ff6b36fa1d03087ea1a...   \n",
       "\n",
       "                            input_final_prompts_hash     benchmark_label  \\\n",
       "0  [adcde01feac66b5a5a928be8804031ffddcb481ef73e4...  MATH (4-shot, CoT)   \n",
       "1  [97745be9a6acd60858e258a46fbd4946e2904dd320c6c...  MATH (4-shot, CoT)   \n",
       "2  [2a840b3673983db48b20ed473579b710ad1f111764425...  MATH (4-shot, CoT)   \n",
       "3  [c7952d5c97db4006ebe8fba59bf41c9caa6dc35c59590...  MATH (4-shot, CoT)   \n",
       "4  [857c3d7d39e2cef68320fb00d5271b66676ba06244744...  MATH (4-shot, CoT)   \n",
       "\n",
       "                                         eval_config  \n",
       "0  {'max_gen_len': '5120', 'max_prompt_len': '307...  \n",
       "1  {'max_gen_len': '5120', 'max_prompt_len': '307...  \n",
       "2  {'max_gen_len': '5120', 'max_prompt_len': '307...  \n",
       "3  {'max_gen_len': '5120', 'max_prompt_len': '307...  \n",
       "4  {'max_gen_len': '5120', 'max_prompt_len': '307...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset_FROM_META_df = eval_dataset_FROM_META['latest'].to_pandas()\n",
    "eval_dataset_FROM_META_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_gen_len': '5120',\n",
       " 'max_prompt_len': '3072',\n",
       " 'num_few_shot': '4',\n",
       " 'num_generations': '1',\n",
       " 'prompt_fn': \"functools.partial(<function jinja_dialog_format at 0x7fe9828b28c0>, template={'prompt': 'Solve the following math problem efficiently and clearly:\\\\n\\\\n- For simple problems (2 steps or fewer):\\\\nProvide a concise solution with minimal explanation.\\\\n\\\\n- For complex problems (3 steps or more):\\\\nUse this step-by-step format:\\\\n\\\\n## Step 1: [Concise description]\\\\n[Brief explanation and calculations]\\\\n\\\\n## Step 2: [Concise description]\\\\n[Brief explanation and calculations]\\\\n\\\\n...\\\\n\\\\nRegardless of the approach, always conclude with:\\\\n\\\\nTherefore, the final answer is: $\\\\\\\\boxed{answer}$. I hope it is correct.\\\\n\\\\nWhere [answer] is just the final number or expression that solves the problem.\\\\n\\\\nProblem: {{ problem }}\\\\n', 'answer': '{{ solution }}. I hope it is correct.'}, append_gen_prefix=False)\",\n",
       " 'return_logprobs': 'false',\n",
       " 'seed': '42',\n",
       " 'temperature': '0.0',\n",
       " 'top_k': '0',\n",
       " 'top_p': '0'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check META's eval_config\n",
    "eval_dataset_FROM_META_df['eval_config'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config = {\n",
    "    'max_gen_len': 5120,\n",
    "    'max_prompt_len': 3072,\n",
    "    'num_few_shot': 4,\n",
    "    'num_generations': 1,\n",
    "    'prompt_fn': \"functools.partial(<function jinja_dialog_format at 0x7fe9828b28c0>, template={'prompt': 'Solve the following math problem efficiently and clearly:\\\\n\\\\n- For simple problems (2 steps or fewer):\\\\nProvide a concise solution with minimal explanation.\\\\n\\\\n- For complex problems (3 steps or more):\\\\nUse this step-by-step format:\\\\n\\\\n## Step 1: [Concise description]\\\\n[Brief explanation and calculations]\\\\n\\\\n## Step 2: [Concise description]\\\\n[Brief explanation and calculations]\\\\n\\\\n...\\\\n\\\\nRegardless of the approach, always conclude with:\\\\n\\\\nTherefore, the final answer is: $\\\\\\\\boxed{answer}$. I hope it is correct.\\\\n\\\\nWhere [answer] is just the final number or expression that solves the problem.\\\\n\\\\nProblem: {{ problem }}\\\\n', 'answer': '{{ solution }}. I hope it is correct.'}, append_gen_prefix=False)\",\n",
    "    'return_logprobs': False,\n",
    "    'seed': 42,\n",
    "    'temperature': 0.0,\n",
    "    'top_k': 0,\n",
    "    'top_p': 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "torch.manual_seed(eval_config['seed'])\n",
    "random.seed(eval_config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess Data\n",
    "\n",
    "Here, we use functions provided by Meta in their Llama recipes (based on llm eval harness): https://github.com/meta-llama/llama-recipes/blob/2501f519c7a775e3fab82ff286916671023ca9c6/tools/benchmarks/llm_eval_harness/meta_eval/meta_template/math_hard/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lm_eval\n",
    "\n",
    "import math_utils\n",
    "import importlib\n",
    "importlib.reload(math_utils) \n",
    "\n",
    "from math_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_dataset_test_processed = process_docs(math_dataset_test) # get numerical answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5205b4900bb14e88bb3da9d168f2f02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "# Add the instruction (and sample problems if few shot) before each problem\n",
    "cot_prompt = \"<|start_header_id|>user<|end_header_id|>\\n\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.\\n\\n\"\n",
    "problems = [\"Find the domain of the expression $\\\\frac{\\\\sqrt{x-2}}{\\\\sqrt{5-x}}$.\",\n",
    "            \"If $\\\\det \\\\mathbf{A} = 2$ and $\\\\det \\\\mathbf{B} = 12,$ then find $\\\\det (\\\\mathbf{A} \\\\mathbf{B}).$\",\n",
    "            \"Terrell usually lifts two 20-pound weights 12 times. If he uses two 15-pound weights instead, how many times must Terrell lift them in order to lift the same total weight?\",\n",
    "            \"If the system of equations\\n\\n\\\\begin{align*}\\n6x-4y&=a,\\\\\\\\\\n6y-9x &=b.\\n\\\\end{align*}has a solution $(x, y)$ where $x$ and $y$ are both nonzero, find $\\\\frac{a}{b},$ assuming $b$ is nonzero.\"]\n",
    "solutions = [\"## Step 1: Consider the expression inside the first square root\\nThe expression inside the first square root is $x-2$, and it must be non-negative. This means that $x-2 \\\\ge 0$, which simplifies to $x \\\\ge 2$.\\n\\n## Step 2: Consider the expression inside the second square root\\nThe expression inside the second square root is $5-x$, and it must be non-negative. This means that $5-x \\\\ge 0$, which simplifies to $x \\\\le 5$.\\n\\n## Step 3: Consider the denominator of the expression\\nThe denominator of the expression is $\\\\sqrt{5-x}$, and it cannot be equal to zero. This means that $5-x>0$, which simplifies to $x<5$.\\n\\n## Step 4: Combine the results from the previous steps\\nCombining the results from the previous steps, we have $x \\\\ge 2$ and $x < 5$. This means that the domain of the expression is $[2,5)$.\\n\\nThe final answer is: $\\\\boxed{[2,5)}$. I hope it is correct.\",\n",
    "             \"## Step 1:  Understand the properties of determinants\\nWe know that the determinant of a product of two matrices is equal to the product of their determinants.\\n\\n## Step 2: Apply the property to the given matrices\\nUsing the property, we can write $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = (\\\\det \\\\mathbf{A})(\\\\det \\\\mathbf{B})$.\\n\\n## Step 3: Substitute the given values\\nWe are given that $\\\\det \\\\mathbf{A} = 2$ and $\\\\det \\\\mathbf{B} = 12$. Substituting these values, we get $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = (2)(12)$.\\n\\n## Step 4: Calculate the final answer\\nEvaluating the product, we find that $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = 24$.\\n\\nThe final answer is: $\\\\boxed{24}$. I hope it is correct.\",\n",
    "             \"## Step 1: Calculate the total weight Terrell lifts with two 20-pound weights\\nTerrell lifts two 20-pound weights 12 times, so the total weight he lifts is $2 \\\\cdot 12 \\\\cdot 20 = 480$ pounds.\\n\\n## Step 2: Calculate the total weight Terrell lifts with two 15-pound weights for n times\\nIf Terrell lifts two 15-pound weights instead for $n$ times, he will lift a total of $2 \\\\cdot 15 \\\\cdot n = 30n$ pounds of weight.\\n\\n## Step 3: Equate the total weight lifted with 15-pound weights to 480 pounds and solve for n\\nEquating the total weight lifted with 15-pound weights to 480 pounds, we can solve for $n$: $30n = 480$.\\n\\n## Step 4: Solve for n\\nTo solve for $n$, divide both sides by 30: $n = \\\\frac{480}{30}$.\\n\\n## Step 5: Calculate the value of n\\nThe value of $n$ is $\\\\frac{480}{30} = 16$.\\n\\nThe final answer is: $\\\\boxed{16}$. I hope it is correct.\",\n",
    "             \"## Step 1: Understand the problem\\nWe are given a system of linear equations with two variables, $x$ and $y$, and two constants, $a$ and $b$. Our goal is to find the ratio $\\\\frac{a}{b}$, assuming $b$ is nonzero.\\n\\n## Step 2: Multiply the first equation by a suitable factor\\nWe multiply the first equation by $-\\\\frac{3}{2}$ to obtain an equation with the same coefficients for $y$ as the second equation: $$-\\\\frac{3}{2}(6x-4y)=a\\\\Rightarrow 6y-9x=-\\\\frac{3}{2}a.$$\\n\\n## Step 3: Equate the right-hand sides of the two equations\\nSince we know that $6y-9x=b$ from the second equation, we can equate the right-hand sides of the two equations to obtain $$-\\\\frac{3}{2}a=b.$$\\n\\n## Step 4: Solve for the ratio $\\\\frac{a}{b}$\\nFinally, we can solve for the ratio $\\\\frac{a}{b}$ by dividing both sides of the equation by $b$, giving us $$\\\\frac{a}{b}=-\\\\frac{2}{3}.$$\\n\\nThe final answer is: $\\\\boxed{-\\\\frac{2}{3}}. I hope it is correct.\"]\n",
    "\n",
    "def add_prompt(question_set, cot_prompt, few_shot = False, problems = None, solutions = None):\n",
    "    \"question set contains 'problem', 'solution', 'type', and 'level'\"\n",
    "    if few_shot and (problems is None or solutions is None):\n",
    "        raise ValueError(\"Few shot prompts require sample problems and answers\")\n",
    "    \n",
    "    prompt = cot_prompt\n",
    "\n",
    "    if few_shot:\n",
    "        # Concatenate problems and answers with the specified formatting\n",
    "        for i in range(len(problems)): \n",
    "            prompt += f\"Problem: {problems[i]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{solutions[i]}<|eot_id|>\"\n",
    "            prompt += cot_prompt\n",
    "        \n",
    "    question_set['input_final_prompt'] = f\"{prompt}Problem: {question_set['problem']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "    return question_set\n",
    "\n",
    "# Create a partial function\n",
    "add_prompt_fewshot_partial = functools.partial(add_prompt, cot_prompt=cot_prompt, few_shot=True, problems=problems, solutions=solutions)\n",
    "\n",
    "# Apply the function to the dataset\n",
    "math_dataset_test_processed = math_dataset_test_processed.map(add_prompt_fewshot_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'Find $x$ such that $\\\\lceil x \\\\rceil + x = \\\\dfrac{23}{7}$. Express $x$ as a common fraction.',\n",
       " 'level': 'Level 4',\n",
       " 'type': 'Algebra',\n",
       " 'solution': 'First, we note that $x$ must be positive, since otherwise $\\\\lceil x \\\\rceil + x$ is nonpositive. Next, we know that the decimal part of $x$ must be $\\\\dfrac{2}{7}$. We write $x$ as $n+\\\\dfrac{2}{7}$, where $n$ is the greatest integer less than $x.$ Then, $\\\\lceil x \\\\rceil = n + 1.$ Therefore, we can write $\\\\lceil x \\\\rceil + x$ as $n+1+n+\\\\dfrac{2}{7}=\\\\dfrac{23}{7}$. Solving, we get $n=1$. Therefore, the only value $x$ that satisfies the equation is $1+\\\\dfrac{2}{7}=\\\\boxed{\\\\dfrac{9}{7}}$.',\n",
       " 'answer': '\\\\dfrac{9}{7}',\n",
       " 'input_final_prompt': '<|start_header_id|>user<|end_header_id|>\\n\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.\\n\\nProblem: Find the domain of the expression $\\\\frac{\\\\sqrt{x-2}}{\\\\sqrt{5-x}}$.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n## Step 1: Consider the expression inside the first square root\\nThe expression inside the first square root is $x-2$, and it must be non-negative. This means that $x-2 \\\\ge 0$, which simplifies to $x \\\\ge 2$.\\n\\n## Step 2: Consider the expression inside the second square root\\nThe expression inside the second square root is $5-x$, and it must be non-negative. This means that $5-x \\\\ge 0$, which simplifies to $x \\\\le 5$.\\n\\n## Step 3: Consider the denominator of the expression\\nThe denominator of the expression is $\\\\sqrt{5-x}$, and it cannot be equal to zero. This means that $5-x>0$, which simplifies to $x<5$.\\n\\n## Step 4: Combine the results from the previous steps\\nCombining the results from the previous steps, we have $x \\\\ge 2$ and $x < 5$. This means that the domain of the expression is $[2,5)$.\\n\\nThe final answer is: $\\\\boxed{[2,5)}$. I hope it is correct.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.\\n\\nProblem: If $\\\\det \\\\mathbf{A} = 2$ and $\\\\det \\\\mathbf{B} = 12,$ then find $\\\\det (\\\\mathbf{A} \\\\mathbf{B}).$<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n## Step 1:  Understand the properties of determinants\\nWe know that the determinant of a product of two matrices is equal to the product of their determinants.\\n\\n## Step 2: Apply the property to the given matrices\\nUsing the property, we can write $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = (\\\\det \\\\mathbf{A})(\\\\det \\\\mathbf{B})$.\\n\\n## Step 3: Substitute the given values\\nWe are given that $\\\\det \\\\mathbf{A} = 2$ and $\\\\det \\\\mathbf{B} = 12$. Substituting these values, we get $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = (2)(12)$.\\n\\n## Step 4: Calculate the final answer\\nEvaluating the product, we find that $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = 24$.\\n\\nThe final answer is: $\\\\boxed{24}$. I hope it is correct.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.\\n\\nProblem: Terrell usually lifts two 20-pound weights 12 times. If he uses two 15-pound weights instead, how many times must Terrell lift them in order to lift the same total weight?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n## Step 1: Calculate the total weight Terrell lifts with two 20-pound weights\\nTerrell lifts two 20-pound weights 12 times, so the total weight he lifts is $2 \\\\cdot 12 \\\\cdot 20 = 480$ pounds.\\n\\n## Step 2: Calculate the total weight Terrell lifts with two 15-pound weights for n times\\nIf Terrell lifts two 15-pound weights instead for $n$ times, he will lift a total of $2 \\\\cdot 15 \\\\cdot n = 30n$ pounds of weight.\\n\\n## Step 3: Equate the total weight lifted with 15-pound weights to 480 pounds and solve for n\\nEquating the total weight lifted with 15-pound weights to 480 pounds, we can solve for $n$: $30n = 480$.\\n\\n## Step 4: Solve for n\\nTo solve for $n$, divide both sides by 30: $n = \\\\frac{480}{30}$.\\n\\n## Step 5: Calculate the value of n\\nThe value of $n$ is $\\\\frac{480}{30} = 16$.\\n\\nThe final answer is: $\\\\boxed{16}$. I hope it is correct.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.\\n\\nProblem: If the system of equations\\n\\n\\\\begin{align*}\\n6x-4y&=a,\\\\\\\\\\n6y-9x &=b.\\n\\\\end{align*}has a solution $(x, y)$ where $x$ and $y$ are both nonzero, find $\\\\frac{a}{b},$ assuming $b$ is nonzero.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n## Step 1: Understand the problem\\nWe are given a system of linear equations with two variables, $x$ and $y$, and two constants, $a$ and $b$. Our goal is to find the ratio $\\\\frac{a}{b}$, assuming $b$ is nonzero.\\n\\n## Step 2: Multiply the first equation by a suitable factor\\nWe multiply the first equation by $-\\\\frac{3}{2}$ to obtain an equation with the same coefficients for $y$ as the second equation: $$-\\\\frac{3}{2}(6x-4y)=a\\\\Rightarrow 6y-9x=-\\\\frac{3}{2}a.$$\\n\\n## Step 3: Equate the right-hand sides of the two equations\\nSince we know that $6y-9x=b$ from the second equation, we can equate the right-hand sides of the two equations to obtain $$-\\\\frac{3}{2}a=b.$$\\n\\n## Step 4: Solve for the ratio $\\\\frac{a}{b}$\\nFinally, we can solve for the ratio $\\\\frac{a}{b}$ by dividing both sides of the equation by $b$, giving us $$\\\\frac{a}{b}=-\\\\frac{2}{3}.$$\\n\\nThe final answer is: $\\\\boxed{-\\\\frac{2}{3}}. I hope it is correct.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.\\n\\nProblem: Find $x$ such that $\\\\lceil x \\\\rceil + x = \\\\dfrac{23}{7}$. Express $x$ as a common fraction.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_dataset_test_processed[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate model outputs and evaluate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_config = {\n",
    "    'max_new_tokens': eval_config['max_gen_len'],\n",
    "    'num_return_sequences': eval_config['num_generations'],\n",
    "    'output_scores': eval_config['return_logprobs'],\n",
    "    'pad_token_id': tokenizer.eos_token_id,\n",
    "    'do_sample': False,  # since temperature, top_k, top_p are 0\n",
    "    'top_p': None,\n",
    "    'temperature': None,\n",
    "    'top_k': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Step 1: Understand the problem\n",
      "We are given an equation involving the ceiling function, which rounds a number up to the nearest integer. The equation is $\\lceil x \\rceil + x = \\dfrac{23}{7}$, and we need to find the value of $x$ as a common fraction.\n",
      "\n",
      "## Step 2: Recognize that $\\lceil x \\rceil$ is an integer\n",
      "Since $\\lceil x \\rceil$ is the ceiling function, it rounds $x$ up to the nearest integer. This means that $\\lceil x \\rceil$ is always an integer.\n",
      "\n",
      "## Step 3: Express $x$ as the sum of an integer and a fraction\n",
      "Let's express $x$ as the sum of an integer $n$ and a fraction $\\frac{f}{7}$, where $f$ is an integer. Then, we have $\\lceil x \\rceil = n$ and $x = n + \\frac{f}{7}$.\n",
      "\n",
      "## Step 4: Substitute $x$ into the original equation\n",
      "Substituting $x = n + \\frac{f}{7}$ into the original equation, we get $\\lceil n + \\frac{f}{7} \\rceil + n + \\frac{f}{7} = \\dfrac{23}{7}$.\n",
      "\n",
      "## Step 5: Simplify the equation\n",
      "Since $\\lceil n + \\frac{f}{7} \\rceil = n + 1$ (because $n$ is an integer and $\\lceil n + \\frac{f}{7} \\rceil$ rounds up to $n$), we can simplify the equation to $n + 1 + n + \\frac{f}{7} = \\dfrac{23}{7}$.\n",
      "\n",
      "## Step 6: Combine like terms\n",
      "Combining like terms, we get $2n + \\frac{f}{7} = \\dfrac{23}{7}$.\n",
      "\n",
      "## Step 7: Solve for $n$\n",
      "Subtracting $\\frac{f}{7}$ from both sides, we get $2n = \\dfrac{23}{7} - \\frac{f}{7}$. Then, dividing both sides by 2, we get $n = \\dfrac{23}{14} - \\dfrac{f}{14}$.\n",
      "\n",
      "## Step 8: Express $x$ as a common fraction\n",
      "Since $x = n + \\frac{f}{7}$, we can substitute $n = \\dfrac{23}{14} - \\dfrac{f}{14}$ into this equation to get $x = \\dfrac{23}{14} - \\dfrac{f}{14} + \\frac{f}{7}$.\n",
      "\n",
      "## Step 9: Simplify the expression for $x$\n",
      "Combining like terms, we get $x = \\dfrac{23}{14} - \\dfrac{f}{14} + \\dfrac{2f}{14}$. Then, combining the $\\dfrac{f}{14}$ terms, we get $x = \\dfrac{23 + 2f}{14}$.\n",
      "\n",
      "The final answer is: $\\boxed{\\dfrac{23 + 2f}{14}}$. I hope it is correct.\n"
     ]
    }
   ],
   "source": [
    "# Generate a sample inference\n",
    "sample_idx = 2\n",
    "\n",
    "input_prompt = math_dataset_test_processed['input_final_prompt'][sample_idx]\n",
    "input_tokenized = tokenizer(input_prompt, return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "output = model.generate(**input_tokenized, \n",
    "                        **generate_config\n",
    "                        )\n",
    "\n",
    "# Find the length of the input tokens\n",
    "input_length = len(input_tokenized.input_ids[0])\n",
    "\n",
    "# Extract the new tokens from the generated output\n",
    "new_tokens = output[0][input_length:]\n",
    "\n",
    "# Decode the new tokens to get the new text\n",
    "new_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Answer: \\dfrac{23+2f}{14}\n"
     ]
    }
   ],
   "source": [
    "output_numerical_answer = normalize_final_answer(remove_boxed(last_boxed_only_string(new_text)))\n",
    "\n",
    "print(\"Numerical Answer:\", output_numerical_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code for generating new text for a batch of examples\n",
    "# def generate_new_text_batch(examples, tokenizer, model, generate_config):\n",
    "#     model.eval()\n",
    "\n",
    "#     input_prompts = examples['input_final_prompt']\n",
    "#     input_tokenized = tokenizer(input_prompts, return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "#     # Generate output for the batch\n",
    "#     output = model.generate(**input_tokenized, **generate_config)\n",
    "\n",
    "#     new_texts = []\n",
    "#     generated_answers = []\n",
    "#     exact_matches = []\n",
    "#     for i in range(len(input_prompts)):\n",
    "#         input_length = len(input_tokenized.input_ids[i])\n",
    "#         new_tokens = output[i][input_length:]\n",
    "\n",
    "#         new_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "#         new_texts.append(new_text)\n",
    "\n",
    "#         last_boxed_string = last_boxed_only_string(new_text)\n",
    "#         if not last_boxed_string:\n",
    "#             # No boxed string found, so we can't evaluate\n",
    "#            generated_answer = None\n",
    "#            exact_match = 0\n",
    "#         else:\n",
    "#             generated_answer = normalize_final_answer(remove_boxed(last_boxed_only_string(new_text)))\n",
    "#             ground_truth_answer = examples['answer'][i]\n",
    "\n",
    "#             if generated_answer.strip() == ground_truth_answer.strip() or is_equiv(generated_answer, ground_truth_answer):\n",
    "#                 exact_match = 1\n",
    "#             else:\n",
    "#                 exact_match = 0\n",
    "#         generated_answers.append(generated_answer)\n",
    "#         exact_matches.append(exact_match)\n",
    "\n",
    "#     # Add the new texts to the examples\n",
    "#     examples['generated_text'] = new_texts\n",
    "#     examples['generated_answer'] = generated_answers\n",
    "#     examples['exact_match'] = exact_matches\n",
    "#     return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94078ec92cb4ba3bcd5f812e4e1e050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Generate new text for the first 10 problems\n",
    "# small_dataset = math_dataset_test_processed.select(range(10))\n",
    "\n",
    "# # Apply the function to the small subset\n",
    "# small_dataset_processed = small_dataset.map(\n",
    "#     lambda examples: generate_new_text_batch(examples, tokenizer, model, generate_config),\n",
    "#     batched=True,\n",
    "#     batch_size=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33eff380bf5c4021b9e05a725cec3057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m math_dataset_test_processed \u001b[38;5;241m=\u001b[39m \u001b[43mmath_dataset_test_processed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_new_text_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Save the processed dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a directory to store the results\u001b[39;00m\n\u001b[1;32m     10\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3035\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3031\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3032\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3033\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3034\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3035\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3036\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3438\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3434\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3435\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3436\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3438\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3442\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3443\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3447\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3300\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3299\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3300\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3302\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3303\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3304\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[87], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      1\u001b[0m math_dataset_test_processed \u001b[38;5;241m=\u001b[39m math_dataset_test_processed\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m examples: \u001b[43mgenerate_new_text_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_config\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      3\u001b[0m     batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Save the processed dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a directory to store the results\u001b[39;00m\n\u001b[1;32m     10\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[81], line 9\u001b[0m, in \u001b[0;36mgenerate_new_text_batch\u001b[0;34m(examples, tokenizer, model, generate_config)\u001b[0m\n\u001b[1;32m      6\u001b[0m input_tokenized \u001b[38;5;241m=\u001b[39m tokenizer(input_prompts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Generate output for the batch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tokenized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m new_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m generated_answers \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/transformers/generation/utils.py:2048\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2040\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2041\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2042\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2043\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2044\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2047\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2048\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2061\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2062\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2068\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/transformers/generation/utils.py:2997\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2994\u001b[0m unfinished_sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(batch_size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2995\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_initial_cache_position(input_ids, model_kwargs)\n\u001b[0;32m-> 2997\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_unfinished_sequences(\n\u001b[1;32m   2998\u001b[0m     this_peer_finished, synced_gpus, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice, cur_len\u001b[38;5;241m=\u001b[39mcur_len, max_length\u001b[38;5;241m=\u001b[39mmax_length\n\u001b[1;32m   2999\u001b[0m ):\n\u001b[1;32m   3000\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[1;32m   3001\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   3003\u001b[0m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# math_dataset_test_processed = math_dataset_test_processed.map(\n",
    "#     lambda examples: generate_new_text_batch(examples, tokenizer, model, generate_config),\n",
    "#     batched=True,\n",
    "#     batch_size=32\n",
    "# )\n",
    "\n",
    "# # Save the processed dataset\n",
    "\n",
    "# # Create a directory to store the results\n",
    "# output_dir = \"outputs\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Save the results to a file\n",
    "# results_file = os.path.join(output_dir, f\"results_4shot.json\")\n",
    "# with open(results_file, \"w\") as f:\n",
    "#     json.dump(math_dataset_test_processed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "  2%|▏         | 4/200 [22:27<18:20:46, 336.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m input_tokenized \u001b[38;5;241m=\u001b[39m tokenizer(input_prompts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Generate output for the batch\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tokenized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m new_texts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m generated_answers \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/transformers/generation/utils.py:2048\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2040\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2041\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2042\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2043\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2044\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2047\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2048\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2061\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2062\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2068\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/transformers/generation/utils.py:2997\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2994\u001b[0m unfinished_sequences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(batch_size, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2995\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_initial_cache_position(input_ids, model_kwargs)\n\u001b[0;32m-> 2997\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_unfinished_sequences(\n\u001b[1;32m   2998\u001b[0m     this_peer_finished, synced_gpus, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice, cur_len\u001b[38;5;241m=\u001b[39mcur_len, max_length\u001b[38;5;241m=\u001b[39mmax_length\n\u001b[1;32m   2999\u001b[0m ):\n\u001b[1;32m   3000\u001b[0m     \u001b[38;5;66;03m# prepare model inputs\u001b[39;00m\n\u001b[1;32m   3001\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   3003\u001b[0m     \u001b[38;5;66;03m# prepare variable output controls (note: some models won't accept all output controls)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "test_data_loader = DataLoader(math_dataset_test_processed, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store results\n",
    "all_generated_texts = []\n",
    "all_generated_answers = []\n",
    "all_exact_matches = []\n",
    "\n",
    "for batch in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "    # Tokenize the batch\n",
    "    input_prompts = batch['input_final_prompt']\n",
    "    input_tokenized = tokenizer(input_prompts, return_tensors=\"pt\", padding=True, truncation=False).to(device)\n",
    "\n",
    "    # Generate output for the batch\n",
    "    output = model.generate(**input_tokenized, **generate_config)\n",
    "\n",
    "    new_texts = []\n",
    "    generated_answers = []\n",
    "    exact_matches = []\n",
    "    for i in range(len(input_prompts)):\n",
    "        input_length = len(input_tokenized.input_ids[i])\n",
    "        new_tokens = output[i][input_length:]\n",
    "        new_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "        new_texts.append(new_text)\n",
    "\n",
    "\n",
    "        last_boxed_string = last_boxed_only_string(new_text)\n",
    "        if not last_boxed_string:\n",
    "            # No boxed string found, so we can't evaluate\n",
    "           generated_answers.append(None)\n",
    "           exact_matches.append(0)\n",
    "        else:\n",
    "            generated_answer = normalize_final_answer(remove_boxed(last_boxed_only_string(new_text)))\n",
    "            ground_truth_answer = batch['answer'][i]\n",
    "\n",
    "            if generated_answer.strip() == ground_truth_answer.strip() or is_equiv(generated_answer, ground_truth_answer):\n",
    "                exact_matches.append(1)\n",
    "            else:\n",
    "                exact_matches.append(0)\n",
    "            generated_answers.append(generated_answer)\n",
    "\n",
    "    # Store results\n",
    "    all_generated_texts.extend(new_texts)\n",
    "    all_generated_answers.extend(generated_answers)\n",
    "    all_exact_matches.extend(exact_matches)\n",
    "\n",
    "# Add the results back to the dataset\n",
    "math_dataset_test_processed['generated_text'] = all_generated_texts\n",
    "math_dataset_test_processed['generated_answer'] = all_generated_answers\n",
    "math_dataset_test_processed['exact_match'] = all_exact_matches\n",
    "\n",
    "# Save the processed dataset\n",
    "\n",
    "# Create a directory to store the results\n",
    "output_dir = \"outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the results to a file\n",
    "results_file = os.path.join(output_dir, f\"results_4shot.json\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(math_dataset_test_processed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EXTENSION: Fine-tune model on MGSM training data (OLD CODE)\n",
    "\n",
    "https://github.com/huggingface/huggingface-llama-recipes/blob/main/fine_tune/peft_finetuning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preprocess train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fields(question_set):\n",
    "    language = question_set['language']\n",
    "    combined_text = f\"{question_set['question']}\\n\\n{question_set['answer']}\\n\\n{question_set['equation_solution']}\\n\\n{answer_translations[language]} {question_set['answer_number']}\"\n",
    "    question_set['text'] = combined_text\n",
    "    return question_set\n",
    "\n",
    "# Apply the function to the dataset\n",
    "mgsm_train_combined = mgsm_train.map(combine_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
      "\n",
      "Step-by-Step Answer: 5 bagels for $3 each should cost 5 * 3 = 15 dollars. Olivia had $23 in the beginning, so now she has 23 - 15 = 8 dollars left. The answer is 8.\n",
      "\n",
      "5 * 3 = 15. 23 - 15 = 8.\n",
      "\n",
      "Answer: 8\n"
     ]
    }
   ],
   "source": [
    "print(mgsm_train_combined['text'][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Fine-tune the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students/ryan/anaconda3/envs/ai231-venv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcayasryan\u001b[0m (\u001b[33mcayasryan-university-of-the-philippines-diliman\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/raid/students/ryan/Cayas-AI-231/machine_exers/ME4/wandb/run-20241011_080416-6d6rslhw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cayasryan-university-of-the-philippines-diliman/huggingface/runs/6d6rslhw' target=\"_blank\">./finetune_results</a></strong> to <a href='https://wandb.ai/cayasryan-university-of-the-philippines-diliman/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cayasryan-university-of-the-philippines-diliman/huggingface' target=\"_blank\">https://wandb.ai/cayasryan-university-of-the-philippines-diliman/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cayasryan-university-of-the-philippines-diliman/huggingface/runs/6d6rslhw' target=\"_blank\">https://wandb.ai/cayasryan-university-of-the-philippines-diliman/huggingface/runs/6d6rslhw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 02:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.304100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.912900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.834600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=110, training_loss=1.0022768627513539, metrics={'train_runtime': 144.5373, 'train_samples_per_second': 6.088, 'train_steps_per_second': 0.761, 'total_flos': 2485041893277696.0, 'train_loss': 1.0022768627513539, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install peft trl bitsandbytes\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from peft import LoraConfig\n",
    "from transformers import BitsAndBytesConfig, EarlyStoppingCallback\n",
    "\n",
    "# UNCOMMENT if need to unload memory\n",
    "# torch.cuda.empty_cache()\n",
    "# del trainer\n",
    "\n",
    "QLoRA = True\n",
    "if QLoRA:\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "    \n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        target_modules=\"all-linear\",\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "else:\n",
    "    lora_config = None\n",
    "\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./finetune_results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_dir='./finetune_logs',\n",
    "    logging_steps=25,\n",
    "    # load_best_model_at_end = True,\n",
    "    # evaluation_strategy = \"steps\",\n",
    "    dataset_text_field=\"text\",  # Set the dataset text field here\n",
    "    max_seq_length=2048  # Set the max sequence length\n",
    ")\n",
    "\n",
    "# tokenizer.padding_side = \"right\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=sft_config,\n",
    "    peft_config=lora_config,\n",
    "    train_dataset=mgsm_train_combined,\n",
    "    # callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/110 [00:00<?, ?it/s]Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "100%|██████████| 110/110 [2:51:32<00:00, 93.57s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Load fine tuned model\n",
    "# del model # delete base model to free up GPU space\n",
    "model_dir = \"./finetune_results/checkpoint-110\"\n",
    "model_finetuned = LlamaForCausalLM.from_pretrained(model_dir)\n",
    "model_finetuned.to(device)\n",
    "\n",
    "# Parameters for batch processing\n",
    "loader_config = {'batch_size': 25,\n",
    "                 'num_workers': 4, \n",
    "                 'prefetch_factor': 2,\n",
    "                 'shuffle': False}\n",
    "\n",
    "# Create a DataLoader for the dataset\n",
    "test_data_loader = DataLoader(mgsm_test, **loader_config)\n",
    "\n",
    "# Initializa a dictionary to store the results\n",
    "results_mgsm_finetuned_2 = {'question': mgsm_test['question'], \n",
    "                'language': mgsm_test['language'], \n",
    "                'ground_truth': mgsm_test['answer_number'], \n",
    "                'generated_answer': []}\n",
    "\n",
    "# Disable parallelism in tokenizers\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Iterate over the DataLoader\n",
    "for batch_samples in tqdm(test_data_loader, total=len(test_data_loader)):\n",
    "\n",
    "    # Add input prompt to the batch problems\n",
    "    batch_problems = [add_input_prompt(question, language) for question, language in zip(batch_samples['question'], batch_samples['language'])]\n",
    "    \n",
    "    # Tokenize the input problems\n",
    "    inputs = tokenizer(batch_problems, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Generate outputs from the model for the entire batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model_finetuned.generate(**inputs, **generate_config)\n",
    "\n",
    "    # Get numerical answer from output texts\n",
    "    output_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    numerical_answers = [maybe_remove_comma(find_number(output_text, answer_translations[language])) for output_text, language in zip(output_texts, batch_samples['language'])]\n",
    "\n",
    "    # Add the numerical answers to the results dictionary\n",
    "    results_mgsm_finetuned_2['generated_answer'].extend(numerical_answers)\n",
    "\n",
    "# Create a directory to store the results\n",
    "output_dir = \"outputs\"\n",
    "results_var_name = \"results_mgsm_finetuned_2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the results to a file\n",
    "results_file = os.path.join(output_dir, f\"{results_var_name}.json\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(globals()[results_var_name], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluate updated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta's Overall Accuracy: 0.24472727272727274\n",
      "Personal Overall Accuracy: 0.1941818181818182\n",
      "\n",
      "   Language  Meta Score  Personal Score  Language Supported\n",
      "0        bn       0.144           0.156               False\n",
      "1        de       0.272           0.232                True\n",
      "2        en       0.420           0.340                True\n",
      "3        es       0.352           0.168                True\n",
      "4        fr       0.264           0.248                True\n",
      "5        ja       0.180           0.160               False\n",
      "6        ru       0.272           0.244               False\n",
      "7        sw       0.184           0.120               False\n",
      "8        te       0.112           0.048               False\n",
      "9        th       0.228           0.188                True\n",
      "10       zh       0.264           0.232               False\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"outputs\"\n",
    "results_var_name = \"results_mgsm_finetuned_2\"\n",
    "\n",
    "# Load the results from the json file and convert to pandas DataFrame\n",
    "results_file = os.path.join(output_dir, f\"{results_var_name}.json\")\n",
    "results_df = pd.read_json(results_file)\n",
    "\n",
    "# Convert ground_truth and generated_answer columns to float\n",
    "results_df['ground_truth'] = results_df['ground_truth'].astype(float)\n",
    "# results_df['generated_answer'] = results_df['generated_answer'].astype(float)\n",
    "results_df['generated_answer'] = pd.to_numeric(results_df['generated_answer'], errors='coerce')\n",
    "    # coerce will convert the invalid parsing to NaN\n",
    "\n",
    "\n",
    "# Compare the generated answers with the ground truth answers\n",
    "results_df['correct'] = results_df['ground_truth'] == results_df['generated_answer']\n",
    "\n",
    "# Get accuracy per language then get average accuracy\n",
    "accuracy_per_language = results_df.groupby('language')['correct'].mean()\n",
    "overall_accuracy = accuracy_per_language.mean()\n",
    "\n",
    "# Get Meta's accuracy\n",
    "meta_accuracy = eval_dataset_FROM_META_df.groupby('subtask_name')['is_correct'].mean()\n",
    "meta_accuracy_overall = meta_accuracy.mean()\n",
    "print(\"Meta's Overall Accuracy:\", meta_accuracy_overall)\n",
    "print(\"Personal Overall Accuracy:\", overall_accuracy)\n",
    "\n",
    "\n",
    "# Check if the language is supported (see https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/blob/main/README.md?code=true)\n",
    "lang_supported = ['en', 'de', 'fr', 'it', 'pt', 'hi', 'es', 'th']\n",
    "is_supported = [lang in lang_supported for lang in accuracy_per_language.index]\n",
    "\n",
    "# Compare Meta and personal evaluation results\n",
    "eval_scores_df = pd.DataFrame({\n",
    "    'Language': meta_accuracy.index,\n",
    "    'Meta Score': meta_accuracy.values,\n",
    "    'Personal Score': accuracy_per_language.values,\n",
    "    'Language Supported': is_supported\n",
    "})\n",
    "\n",
    "print('')\n",
    "print(eval_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted the fine-tuned model weights in ./finetune_results\n"
     ]
    }
   ],
   "source": [
    "# Delete the fine-tuned model weights\n",
    "model_dir = \"./finetune_results\"\n",
    "if os.path.exists(model_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(model_dir)\n",
    "    print(f\"Deleted the fine-tuned model weights in {model_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai231-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
